{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold,GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import warnings\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utility functions to print out reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "def print_regression_report(y_val, y_pred, fold):\n",
    "    print(f'Fold: {fold}')\n",
    "    print('Mean absolute error:', mean_absolute_error(y_val, y_pred))\n",
    "    print('Mean squared error:', mean_squared_error(y_val, y_pred))\n",
    "    print('Root Mean squared error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "\n",
    "def print_classification_report(y_val, y_pred, fold):\n",
    "    print(f'Fold: {fold}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_val, y_pred)}')\n",
    "    print(f'Confusion Matrix: \\n {confusion_matrix(y_val, y_pred)}')\n",
    "    print(f'Classification Report: \\n {classification_report(y_val, y_pred)}')\n",
    "\n",
    "def print_multilabel_classification_report(y_val, y_pred, fold):\n",
    "    print(f'Fold: {fold}')\n",
    "    print(f'Accuracy Score: {accuracy_score(y_val, y_pred)}')\n",
    "    print(f'Confusion Matrix: \\n {confusion_matrix(y_val.argmax(axis=1), y_pred.argmax(axis=1))}')\n",
    "    print(f'Classification Report: \\n {classification_report(y_val, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0           1                    2      3\n",
      "0    body_text  phrase ids     sentiment values  label\n",
      "1          ! '       22935              0.52778    NaN\n",
      "2         ! ''       18235                  0.5    NaN\n",
      "3       ! Alas      179257  0.44443999999999995    NaN\n",
      "4  ! Brilliant       22936              0.86111    NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/pgsdky714yx9znx_f38016kdvtsz5p/T/ipykernel_6177/1517110672.py:1: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('datasets/sentiment/stanford.csv', encoding='latin-1', header=None)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/sentiment/stanford.csv', encoding='latin-1', header=None)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/pgsdky714yx9znx_f38016kdvtsz5p/T/ipykernel_6177/1598307123.py:4: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='latin-1', header=None)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'body text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Python/3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Python/3.8/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'body text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mfit_transform(y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y, data\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m X, y, data \u001b[39m=\u001b[39m read_data(\u001b[39m'\u001b[39;49m\u001b[39mdatasets/sentiment/stanford.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#indices = random.sample(range(len(data)), sample_size)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m X, y \u001b[39m=\u001b[39m X[indices], y[indices]\n",
      "\u001b[1;32m/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb Cell 6\u001b[0m in \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_data\u001b[39m(file_path):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin-1\u001b[39m\u001b[39m'\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     X, y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mbody text\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalues,  data[\u001b[39m'\u001b[39m\u001b[39msentiment values\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/amazon_sentiment_analysis_2.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m y[i] \u001b[39m<\u001b[39m \u001b[39m0.33\u001b[39m: \n",
      "File \u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Python/3.8/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'body text'"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path, encoding='latin-1', header=None)\n",
    "    X, y = data['body_text'].values,  data['sentiment values'].values\n",
    "    for i in range(len(y)):\n",
    "        if y[i] < 0.33: \n",
    "            y[i] = 0\n",
    "        elif y[i] < 0.66:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 2\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    return X, y, data\n",
    "\n",
    "X, y, data = read_data('datasets/sentiment/stanford.csv')\n",
    "#indices = random.sample(range(len(data)), sample_size)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "print(f'size of data: {len(X)}, shape of X: {X.shape}, shape of y: {y.shape}')\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=15000, ngram_range=(1, 2), lowercase=True)\n",
    "    vectorizer.fit(X_train)\n",
    "\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "    X_val = vectorizer.transform(X_val)\n",
    "\n",
    "    model = XGBRegressor(n_estimators=1000, learning_rate=0.1, max_depth=10, n_jobs=-1, random_state=42, subsample=0.8, colsample_bytree=0.8)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.round(y_pred)\n",
    "    print_classification_report(y_val, y_pred, fold)\n",
    "    fold += 1\n",
    "\n",
    "    misclassified = np.where(y_val != y_pred)\n",
    "    misclassified_labels = y_val[misclassified]\n",
    "    misclassified_predictions = y_pred[misclassified]\n",
    "    misclassified_reviews = data['text'].values[misclassified]\n",
    "\n",
    "    indices = random.sample(range(len(misclassified_labels)), 10)\n",
    "\n",
    "    for i in indices:\n",
    "        print(f'Review: {misclassified_reviews[i]}, Actual: {misclassified_labels[i]}, Predicted: {misclassified_predictions[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model('sentiment_analysis.model')\n",
    "joblib.dump(vectorizer, 'vectorizer.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of data: 200000, shape of X: (200000,), shape of y: (200000,)\n",
      "Fold: 16\n",
      "Accuracy Score: 0.79135\n",
      "Confusion Matrix: \n",
      " [[15579  4456]\n",
      " [ 3890 16075]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79     20035\n",
      "           1       0.78      0.81      0.79     19965\n",
      "\n",
      "    accuracy                           0.79     40000\n",
      "   macro avg       0.79      0.79      0.79     40000\n",
      "weighted avg       0.79      0.79      0.79     40000\n",
      "\n",
      "Review: underworld will be down soon , Actual: 0, Predicted: 1\n",
      "Review: off to coventry , Actual: 0, Predicted: 1\n",
      "Review: @ashliewins boooo i got this tweet late. im outtie to pool parties , Actual: 1, Predicted: 0\n",
      "Review: wahhh school  unbelieveably jealous of @JasmineBagci, she went on holiday to turkey yesterday!, Actual: 0, Predicted: 1\n",
      "Review: Sprained ankle- doctor says I can't play tennis for 3 weeks! , Actual: 0, Predicted: 1\n",
      "Review: ok shower &amp; baack to reality! , Actual: 1, Predicted: 0\n",
      "Review: laying in bed milking the sickness.  too bad no one is here to take care of me.  , Actual: 0, Predicted: 1\n",
      "Review: @Sweena How do I do that? The page won't load at all , Actual: 0, Predicted: 1\n",
      "Review: @elodiegrossi Yeap, Linguistics here, actually EFL so a lot of linguistics . Iï¿½m geek for real  Literature sounds lovely!, Actual: 0, Predicted: 1\n",
      "Review:  no luck no one has responed yet I don't think anyone crossed their fingers for me lol come on people this is a team effort lol, Actual: 0, Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "def round_to_nearest(number):\n",
    "    rounded = round(number)\n",
    "    if rounded < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path, encoding='latin-1', header=None)\n",
    "    data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "    X, y = data['text'].values,  data['target'].values\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    return X, y, data\n",
    "\n",
    "sample_size = 200000\n",
    "X, y, data = read_data('datasets/sentiment/twitter.csv')\n",
    "indices = random.sample(range(len(data)), sample_size)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(f'size of data: {len(X)}, shape of X: {X.shape}, shape of y: {y.shape}')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=15000, ngram_range=(1, 2), lowercase=True)\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, learning_rate=0.1, max_depth=10, n_jobs=-1, random_state=42, subsample=0.8, colsample_bytree=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.round(y_pred)\n",
    "print_classification_report(y_val, y_pred, fold)\n",
    "fold += 1\n",
    "\n",
    "misclassified = np.where(y_val != y_pred)\n",
    "misclassified_labels = y_val[misclassified]\n",
    "misclassified_predictions = y_pred[misclassified]\n",
    "misclassified_reviews = data['text'].values[misclassified]\n",
    "\n",
    "indices = random.sample(range(len(misclassified_labels)), 10)\n",
    "\n",
    "for i in indices:\n",
    "    print(f'Review: {misclassified_reviews[i]}, Actual: {misclassified_labels[i]}, Predicted: {misclassified_predictions[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_twitter.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model('sentiment_analysis_twitter.model')\n",
    "joblib.dump(vectorizer, 'vectorizer_twitter.joblib', compress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
