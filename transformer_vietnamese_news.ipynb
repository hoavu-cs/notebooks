{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trang chính  internet society  internet society hay isoc là một tổ chức quốc tế hoạt động phi lợi nhuận phi chính phủ và bao gồm các thành viên có trình độ chuyên ngành tổ chức này chú trọng đến tiêu chuẩn giáo dục và các vấn đề về chính sách với trên một bốn năm tổ chức thành viên và sáu năm không không không thành viên cá nhân isoc bao gồm những con người cụ thể trong cộng đồng internet mọi chi tiết có thể tìm thấy tại website của isoc   internet society nằm ở gần thủ đô washington dc hoa kỳ và geneva thụy sĩ số hội viên của nó bao gồm hơn một bốn năm tổ chức thành viên và hơn sáu năm không không không cá nhân thành viên còn có thể tự lập một chi nhánh của tổ chức tùy theo vị trí hoặc sở thích hiện nay tổ chức có tới chín không chi nhánh trên toàn thế giới   nhiệm vụ và mục đích hoạt động  bảo đảm cổ vũ cho sự phát triển mở rộng và sử dụng internet được thuận lợi nhất cho mọi người trên toàn thế giới   xem thêm   lịch sử internet  liên kết ngoài   isoc việt nam  trang chủ toàn cầu  ietf and the internet society về internet engineering task force và isoc bài của vint cerf một tám sáu một chín chín năm   l association internationale de lutte contre la cybercriminalité bản lưu  public interest registry  tiếng việt  tiếng việt còn gọi tiếng việt nam hay việt ngữ là ngôn ngữ của người việt và là ngôn ngữ chính thức tại việt nam đây là tiếng mẹ đẻ của khoảng tám năm phần trăm dân cư việt nam cùng với hơn bốn triệu người việt hải ngoại tiếng việt còn là ngôn ngữ thứ hai của các dân tộc thiểu số tại việt nam mặc dù tiếng việt có một số từ vựng vay mượn từ tiếng hán và trước đây dùng chữ nôm một hệ chữ dựa trên chữ hán để viết nhưng tiếng việt được coi là một trong số các ngôn ngữ thuộc ngữ hệ nam á có số người nói nhiều nhất ngày nay tiếng việt dùng bảng chữ cái latinh gọi là chữ quốc ngữ cùng các dấu thanh để viết   tiếng việt được chính thức ghi nhận trong hiến pháp nước cộng hòa xã hội chủ nghĩa việt nam hai không một ba tại chương i điều năm mục ba là ngôn ngữ quốc gia của việt nam tiếng việt bao gồm cách phát âm tiếng việt và chữ quốc ngữ để viết tuy nhiên hiện chưa có bất kỳ văn bản nào ở cấp nhà nước quy định giọng chuẩn và quốc tự của tiếng việt hiện nay phần lớn các văn bản trong nước được viết theo những quy định về chính tả tiếng việt và về thuật ngữ tiếng việt áp dụng cho các sách giáo khoa báo và văn bản của ngành giáo dục nêu tại quyết định của bộ giáo dục số hai bốn không qđ ngày năm tháng ba năm một chín tám bốn do những người thụ hưởng giáo dục đó sau này ra làm việc trong mọi lĩnh vực xã hội   cũng cần lưu ý tránh nhầm lẫn với việt ngữ hay tiếng quảng đông một ngôn ngữ được sử dụng ở miền nam trung quốc cũng như ở hồng kông và ma cao   tổ chức tiêu chuẩn hóa quốc tế đặt mã ngôn ngữ hai chữ cái cho tiếng việt là vi và đặt mã ngôn ngữ ba chữ cái cho tiếng việt là vie   xếp loại  với những cơ sở khoa học gần đây được đa số các nhà ngôn ngữ học thừa nhận tiếng việt có quan hệ gần gũi với tiếng mường và được xếp vào ngữ chi việt thuộc nhóm ngôn ngữ môn khmer trong hệ nam á ở khu vực đông nam á hiện nay   những ngôn ngữ này có chung một số từ vựng căn bản thí dụ từ tay trong tiếng việt tương đương trong tiếng mường là thay trong tiếng khmer là đay và trong tiếng môn là tai   lịch sử  tiếng việt là ngôn ngữ có nguồn gốc bản địa xuất thân từ nền văn minh nông nghiệp tại nơi mà ngày nay là khu vực phía bắc lưu vực sông hồng và sông mã của việt nam   theo a g haudricourt giải thích từ năm một chín năm bốn nhóm ngôn ngữ việt mường ở thời kỳ khoảng đầu công nguyên là những ngôn ngữ hay phương ngữ không thanh điệu về sau qua quá trình giao thoa với hoa ngữ và nhất là với các ngữ thuộc ngữ hệ tai kadai vốn có hệ thống thanh điệu phát triển cao hệ thống thanh điệu trong tiếng việt xuất hiện và có diện mạo như ngày nay theo quy luật hình thành thanh điệu sự xuất hiện các thanh điệu bắt đầu khoảng thế kỷ thứ vi với ba thanh điệu và phát triển ổn định vào khoảng thế kỷ xii với sáu thanh điệu sau đó một số phụ âm đầu biến đổi cho tới ngày nay trong quá trình biến đổi các phụ âm cuối rụng đi làm thay đổi các kết thúc âm tiết và phụ âm đầu chuyển từ lẫn lộn vô thanh với hữu thanh sang tách biệt   ví dụ của a g haudricourt  ảnh hưởng từ trung hoa  tiếng việt là ngôn ngữ dùng trong sinh hoạt giao tiếp của dân thường từ khi lập nước giai đoạn từ đầu công nguyên tiếng việt có rất nhiều âm không có trong tiếng trung từ khi tiếng trung có ảnh hưởng tới việt nam thông qua nhiều con đường và bao gồm nhiều giai đoạn khác nhau tiếng việt bắt đầu có những âm được vay mượn từ tiếng trung các tác giả mai ngọc chừ vũ đức nghiệu và hoàng trọng phiến trong cuốn sách cơ sở ngôn ngữ học và tiếng việt chia quá trình tiếp xúc hán việt thành hai giai đoạn lớn   giai đoạn từ đầu công nguyên đến đầu thời nhà đường từ vựng tiếng hán ảnh hưởng tới tiếng việt trong giai đoạn này gọi là từ hán cổ   giai đoạn từ thời nhà đường trở về sau từ vựng tiếng hán ảnh hưởng tới tiếng việt trong giai đoạn này gọi là từ hán việt   từ hán cổ và từ hán việt được gọi chung là từ gốc hán   một số từ ngữ hán cổ có thể kể đến như đầu gan ghế ông bà cô chè ngà chén chém chìm buồng buồn buồm mùi mùa từ hán cổ là những từ gốc hán được du nhập vào tiếng việt đã lâu đã được đồng hoá rất mạnh nên những từ này hiện nay là từ thông thường trong hoạt động xã hội đối với người việt   hệ thống hán việt trong tiếng việt bằng cách đọc các chữ hán theo ngữ âm hiện có của tiếng việt số lượng từ vựng tiếng việt có thêm hàng loạt các yếu tố hán việt như là chủ ở tâm minh đức thiên tự do giữ nguyên nghĩa chỉ khác cách đọc hay thay đổi vị trí như nhiệt náo thành náo nhiệt thích phóng thành phóng thích đảm bảo thành bảo đảm hoặc được rút gọn như thừa trần thành trần lạc hoa sinh thành lạc hoặc được đọc chệch đi như tiếp thu thành tiếp thụ tháp nhập thành sáp nhập thống kế thành thống kê chúng cư thành chung cư vãn cảnh thành vãng cảnh khuyến mãi thành khuyến mại hay đổi khác nghĩa hoàn toàn như phương phi trong tiếng hán có nghĩa là hoa cỏ thơm tho thì trong tiếng việt lại là béo tốt bồi hồi trong tiếng hán nghĩa là đi đi lại lại sang tiếng việt thành bồn chồn xúc động mặt khác người trung quốc gọi là thái sơn hoàng hà cổ thụ thì người việt lại đọc là núi thái sơn sông hoàng hà cây cổ thụ do tính quy ước của ngôn ngữ mà ít nhiều các cách đọc sai khác với tiếng hán vẫn được chấp nhận và sử dụng rộng rãi trong khi các nhà nghiên cứu ngôn ngữ tiếng việt hiện nay cũng như các cơ quan các cấp quản lý tổ chức xã hội nghề nghiệp lẫn các nhà khoa học việt nam chưa tìm được tiếng nói chung trong việc chuẩn hoá cách sử dụng tên riêng và từ vựng mượn từ tiếng nước ngoài bên cạnh đó cũng có những từ được cho là dùng sai và khó chấp nhận như quan ngại được dùng và hiểu như lo ngại vấn nạn được hiểu là vấn đề nan giải vô hình trung thì viết thành vô hình chung hay vô hình dung việt dã bị hiểu là chạy dài trứ tác được dùng như sáng tác phong thanh được dùng như phong phanh bàng quan được dùng như bàng quang đào ngũ được dùng là đảo ngũ tham quan thành thăm quan xán lạn thành sáng lạng   đặc biệt là các yếu tố hán việt được sử dụng để tạo nên những từ ngữ đặc trưng chỉ có trong tiếng việt không có trong tiếng hán như là các từ sĩ diện phi công hay bao gồm sống động sinh đẻ nói chung tỉ lệ vay mượn tiếng hán trong tiếng việt rất lớn theo ước lượng của các nhà nghiên cứu từ hán việt chiếm khoảng trên dưới bảy không phần trăm vốn từ trong phong cách chính luận khoa học tác giả lê nguyễn lưu trong cuốn sách từ chữ hán đến chữ nôm thì cho rằng về lĩnh vực chuyên môn và khoa học tỉ lệ này có thể lên đến tám không phần trăm nhưng khi nhận xét về văn ngữ trong một cuốn tiểu thuyết thì chỉ còn một hai tám phần trăm kịch nói rút xuống còn tám chín phần trăm và ngôn ngữ nói chuyện hằng ngày còn thấp hơn nữa dù ở tỷ lệ nào đi nữa đại đa số những từ đó đều đã được việt hóa cho phù hợp với nhận thức của người việt tiếng việt gọi là thủ tướng nhưng tiếng hoa là tổng lý tiếng việt là truyền hình thì tiếng hoa là điện thị tiếng việt là thành phố thì tiếng hoa là đô thị những chữ thủ tướng truyền hình thành phố hoàn toàn là hán việt nhưng người hoa tuyệt nhiên không dùng do vậy tiếng việt dù vay mượn tiếng hán nhưng giữ được bản sắc riêng của mình trước ảnh hưởng của văn hóa hán trong khi lợi dụng được những thành tựu ngôn ngữ trong tiếng hán để tự cải tiến mình   kể từ đầu thế kỷ thứ xi nho học phát triển việc học văn tự chữ nho được đẩy mạnh tầng lớp trí thức được mở rộng tạo tiền đề cho một nền văn chương của người việt bằng chữ nho cực kỳ phát triển với cái áng văn thư nổi tiếng như nam quốc sơn hà bên sông như nguyệt   cùng thời gian này một hệ thống chữ viết được xây dựng riêng cho người việt theo nguyên tắc ghi âm tiết được phát triển và đó chính là chữ nôm để tiện cho việc học chữ hán và chữ nôm của người việt ngô thì nhậm đã biên soạn cuốn sách tam thiên tự giải âm tam thiên tự giải âm chỉ lược dạy ba không không không chữ hán nôm thông thường đáp ứng nhu cầu cần thiết nhớ chữ nhớ nghĩa từng chữ mỗi câu bốn chữ hiệp vần cũng có điểm đặc biệt tức là vần lưng tiếng thứ tư câu đầu hiệp với tiếng thứ hai câu dưới rồi cứ thế mãi đến ba không không không chữ bảy năm không câu ví dụ thiên trời địa đất cử cất tồn còn tử con tôn cháu lục sáu tam ba gia nhà quốc nước tiền trước hậu sau ngưu trâu mã ngựa cự cựa nha răng vô chăng hữu có khuyển chó dương dê v v trần văn giáp đánh giá đây tuy chỉ là quyển sách dạy học vỡ lòng về chữ hán như lời tác giả đã nói nhưng thực ra cũng có thể coi nó chính là sách tự điển hán việt thông thường và phổ biến ở cuối thế kỷ xviii cùng thời với các sách chỉ nam ngọc âm chỉ nam bị loại và xuất hiện trước các sách nhật dụng thường đàm thiên tự văn và đại nam quốc ngữ nhờ có chữ nôm văn học việt nam đã có những bước phát triển rực rỡ nhất đạt đỉnh cao với truyện kiều của nguyễn du tiếng việt được thể hiện bằng chữ nôm ở những thời kỳ sau này về cơ bản rất gần với tiếng việt ngày nay tuy hầu hết mọi người việt đều có thể nghe và hiểu văn bản bằng chữ nôm chỉ những người có học chữ nôm mới\n"
     ]
    }
   ],
   "source": [
    "block_size = 500\n",
    "torch.manual_seed(101)\n",
    "\n",
    "filename = 'datasets/text/vietnamese_articles.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print(df.head(10))\n",
    "data = df['Contents']\n",
    "data.dropna(inplace=True)\n",
    "data = data.values.tolist()\n",
    "\n",
    "print(data[:10])\n",
    "\n",
    "special_token = b'\\x03'\n",
    "\n",
    "for idx in range(len(data)):\n",
    "    if len(data[idx]) > block_size:\n",
    "        data[idx] = data[idx][:block_size]\n",
    "    else:\n",
    "        data[idx] = data[idx] + ' '* (block_size - len(data[idx]))\n",
    "    data[idx] = data[idx] \n",
    "\n",
    "text = ' '.join(data)\n",
    "text_set = set(text)\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(sorted(text_set))}\n",
    "itos = {i: ch for i, ch in enumerate(sorted(text_set))}\n",
    "\n",
    "vocab_size = len(stoi)\n",
    "encode = lambda x: torch.tensor([stoi[ch] for ch in x], dtype=torch.long)\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "n_train = int(len(data) * 0.9)\n",
    "train_data = [encode(data[i]) for i in range(n_train)]\n",
    "val_data = [encode(data[i]) for i in range(n_train, len(data))]\n",
    "\n",
    "print(f'vocab_size = {vocab_size}, n_train = {n_train}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) / (C**0.5)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = F.dropout(wei, p=dropout)\n",
    "        # perform score aggregation\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_emb, n_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        x = self.proj(x)\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_emb, 4*n_emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_emb, n_emb),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer Block followed by computation\n",
    "    \"\"\"\n",
    "    def __init__(self, n_emb, n_heads):\n",
    "        super().__init__()\n",
    "        self.head_size = n_emb // n_heads\n",
    "        self.sa = MultiHeadAttention(n_heads, self.head_size)\n",
    "        self.ff = FeedForward()\n",
    "        self.ln1 = nn.LayerNorm(n_emb)\n",
    "        self.ln2 = nn.LayerNorm(n_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        return x\n",
    "        \n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_emb):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
    "        self.blocks = nn.Sequential(*[Block(n_emb, n_heads) for _ in range(n_layers)])\n",
    "        self.feed_forward = FeedForward()\n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(idx)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) \n",
    "        x = token_emb + position_emb\n",
    "        x = self.blocks(x) \n",
    "        x = self.feed_forward(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self.forward(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_new = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_new], dim=-1)\n",
    "        return idx\n",
    "\n",
    "batch_size = 32\n",
    "n_emb = 500\n",
    "n_layers = 6\n",
    "n_heads = 5\n",
    "dropout = 0.2\n",
    "learning_rate = 3e-4\n",
    "\n",
    "m = LanguageModel(vocab_size=vocab_size, n_emb=n_emb).to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 500])\n",
      "torch.Size([32, 500])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_random_subtensors(x, block_size, pad_value=0):\n",
    "    original_len = x.shape[0]\n",
    "    pad_value = encode(' ').item()\n",
    "    \n",
    "    # Check and pad if necessary\n",
    "    if block_size >= original_len:\n",
    "        padded_tensor = torch.full((block_size + 1,), pad_value, dtype=x.dtype)\n",
    "        padded_tensor[:original_len] = x\n",
    "        x = padded_tensor\n",
    "    \n",
    "    # Get a random start index\n",
    "    start_index = random.randint(0, len(x) - block_size - 1)\n",
    "    \n",
    "    # Extract the subtensors\n",
    "    subtensor1 = x[start_index:start_index + block_size]\n",
    "    subtensor2 = x[start_index + 1:start_index + block_size + 1]\n",
    "    \n",
    "    return subtensor1, subtensor2\n",
    "\n",
    "\n",
    "def get_batch(data, block_size, batch_size):\n",
    "    idx = torch.randint(0, len(data)-1, (batch_size,))\n",
    "    seq = []\n",
    "    targets = []\n",
    "    for i in range(batch_size):\n",
    "        s, t = get_random_subtensors(data[idx[i].item()], block_size)\n",
    "        seq.append(s)\n",
    "        targets.append(t)\n",
    "    x = torch.stack([seq[i] for i in range(batch_size)])\n",
    "    y = torch.stack([targets[i] for i in range(batch_size)])\n",
    "    return x, y\n",
    "\n",
    "def estimate_loss(model, val_data, block_size, batch_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = get_batch(val_data, block_size, batch_size)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, loss = model(x, y)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "x, y = get_batch(train_data, block_size, 32)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training Loss: 6.0964860916137695\n",
      "Validation loss: 4.826101779937744\n",
      "Step: 100 Training Loss: 2.4732227325439453\n",
      "Validation loss: 2.5854413509368896\n",
      "Step: 200 Training Loss: 2.472409725189209\n",
      "Validation loss: 2.566506862640381\n",
      "Step: 300 Training Loss: 2.4316163063049316\n",
      "Validation loss: 2.55800724029541\n",
      "Step: 400 Training Loss: 2.4098002910614014\n",
      "Validation loss: 2.53421688079834\n",
      "Step: 500 Training Loss: 2.375126838684082\n",
      "Validation loss: 2.509629726409912\n",
      "Step: 600 Training Loss: 2.3219563961029053\n",
      "Validation loss: 2.4438674449920654\n",
      "Step: 700 Training Loss: 2.270829677581787\n",
      "Validation loss: 2.309495687484741\n",
      "Step: 800 Training Loss: 2.159480094909668\n",
      "Validation loss: 2.2062785625457764\n",
      "Step: 900 Training Loss: 2.0344676971435547\n",
      "Validation loss: 2.1869852542877197\n",
      "Step: 1000 Training Loss: 1.9721791744232178\n",
      "Validation loss: 2.078052282333374\n",
      "Step: 1100 Training Loss: 1.9227980375289917\n",
      "Validation loss: 2.037269353866577\n",
      "Step: 1200 Training Loss: 1.915468692779541\n",
      "Validation loss: 2.0301244258880615\n",
      "Step: 1300 Training Loss: 1.894675850868225\n",
      "Validation loss: 1.9830877780914307\n",
      "Step: 1400 Training Loss: 1.8211843967437744\n",
      "Validation loss: 2.0274710655212402\n",
      "Step: 1500 Training Loss: 1.8354989290237427\n",
      "Validation loss: 1.934718370437622\n",
      "Step: 1600 Training Loss: 1.8086390495300293\n",
      "Validation loss: 1.9123132228851318\n",
      "Step: 1700 Training Loss: 1.7562111616134644\n",
      "Validation loss: 1.8707947731018066\n",
      "Step: 1800 Training Loss: 1.7841379642486572\n",
      "Validation loss: 1.8700650930404663\n",
      "Step: 1900 Training Loss: 1.7477680444717407\n",
      "Validation loss: 1.876309871673584\n",
      "Step: 2000 Training Loss: 1.7362607717514038\n",
      "Validation loss: 1.8802913427352905\n",
      "Step: 2100 Training Loss: 1.6299628019332886\n",
      "Validation loss: 1.8019167184829712\n",
      "Step: 2200 Training Loss: 1.650407314300537\n",
      "Validation loss: 1.7968966960906982\n",
      "Step: 2300 Training Loss: 1.6982243061065674\n",
      "Validation loss: 1.8068267107009888\n",
      "Step: 2400 Training Loss: 1.653509497642517\n",
      "Validation loss: 1.8268585205078125\n",
      "Step: 2500 Training Loss: 1.6683449745178223\n",
      "Validation loss: 1.86655855178833\n",
      "Step: 2600 Training Loss: 1.6621410846710205\n",
      "Validation loss: 1.7851766347885132\n",
      "Step: 2700 Training Loss: 1.72458016872406\n",
      "Validation loss: 1.7379955053329468\n",
      "Step: 2800 Training Loss: 1.6305526494979858\n",
      "Validation loss: 1.7823221683502197\n",
      "Step: 2900 Training Loss: 1.5877176523208618\n",
      "Validation loss: 1.7581112384796143\n",
      "Step: 3000 Training Loss: 1.5717308521270752\n",
      "Validation loss: 1.7254958152770996\n",
      "Step: 3100 Training Loss: 1.5797051191329956\n",
      "Validation loss: 1.7278945446014404\n",
      "Step: 3200 Training Loss: 1.4736593961715698\n",
      "Validation loss: 1.688906192779541\n",
      "Step: 3300 Training Loss: 1.5784850120544434\n",
      "Validation loss: 1.7831331491470337\n",
      "Step: 3400 Training Loss: 1.544184923171997\n",
      "Validation loss: 1.7365367412567139\n",
      "Step: 3500 Training Loss: 1.4983633756637573\n",
      "Validation loss: 1.7269994020462036\n",
      "Step: 3600 Training Loss: 1.5740399360656738\n",
      "Validation loss: 1.7185159921646118\n",
      "Step: 3700 Training Loss: 1.524238109588623\n",
      "Validation loss: 1.6221798658370972\n",
      "Step: 3800 Training Loss: 1.5456143617630005\n",
      "Validation loss: 1.6604756116867065\n",
      "Step: 3900 Training Loss: 1.4577211141586304\n",
      "Validation loss: 1.7429629564285278\n"
     ]
    }
   ],
   "source": [
    "early_stop = 10\n",
    "last_val_loss = 1e9\n",
    "n_epochs = 4000\n",
    "\n",
    "for steps in range(n_epochs):\n",
    "    xb, yb = get_batch(train_data, block_size, batch_size)\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 100 == 0:\n",
    "        print('Step:', steps, 'Training Loss:', loss.item())\n",
    "        val_loss = estimate_loss(m, val_data, block_size, batch_size)\n",
    "        print('Validation loss:', val_loss)\n",
    "        if val_loss >= last_val_loss:\n",
    "            early_stop -= 1\n",
    "            if early_stop == 0:\n",
    "                print('Early stop!')\n",
    "                break\n",
    "        else:\n",
    "            early_stop = 10\n",
    "            last_val_loss = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20700918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hvutr\\AppData\\Local\\Temp\\ipykernel_7724\\2802229414.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  idx = torch.tensor(encode(starting_tokens)).reshape(1, len_starting_tokens).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Việt Nam Giáo dục và Phỏ Giám đối với nồi sau tới đại diện tập triệu lớn phải chính của Trung của Ban Tis Nam Trủ (261 - Môi La Trăng Al) trở giá đốc cần 9 đơn vịch sớm Sài giao số hiêm ngày 22.26,7 điểm khộ giải qua án vong địa và 1960.000 độ C/2020, 81 triệu đồng/kỳ 20220, cùng hỗn mạng việc công tác doanh nghiệp 1015; ngâng là góp tạphổ từ cung phiên tốt tử DN 207 caous với trò, phiên tương; động có 2 người đủ 35-625 - 500-80,05%.000 điểm, và thị tích công tác tiếng, kỹ - xét minh NLĐ. Lạng,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in m.parameters() if p.requires_grad))\n",
    "starting_tokens = 'Việt Nam'\n",
    "len_starting_tokens = len(starting_tokens)\n",
    "idx = torch.tensor(encode(starting_tokens)).reshape(1, len_starting_tokens).to(device)\n",
    "print(decode(m.generate(idx, max_new_tokens=5000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
