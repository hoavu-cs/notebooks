{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hvutr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/text/clean_tales.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the SentencePiece model\n",
    "spm.SentencePieceTrainer.train('--input=datasets/text/clean_tales.txt --model_prefix=datasets/text/clean_tales --vocab_size=3000')\n",
    "sp = spm.SentencePieceProcessor(model_file='datasets/text/clean_tales.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = sp.encode(text, out_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 5797343\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of tokens: {len(text_ids)}')\n",
    "\n",
    "train_size = int(len(text_ids) * 0.8)\n",
    "train_ids = torch.tensor(text_ids[:train_size], dtype=torch.long)\n",
    "val_ids = torch.tensor(text_ids[train_size:], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters 10507240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def estimate_loss(model, val_data, block_size, batch_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = get_batch(val_data, block_size, batch_size)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, loss = model(x, y)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.tril(torch.ones(sz, sz)) == 1).float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "    \n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_emb, n_layers, n_heads, dropout=0.2):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=n_emb, nhead=n_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_emb, 4 * n_emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_emb, n_emb)\n",
    "        )\n",
    "        \n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(idx)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
    "        \n",
    "        x = token_emb + position_emb\n",
    "        x_transform = x.clone()\n",
    "        mask = generate_square_subsequent_mask(T).to(device)\n",
    "        \n",
    "        x_transform = self.transformer_encoder(x_transform.permute(1, 0, 2), mask=mask)\n",
    "        x_transform = x_transform.permute(1, 0, 2)\n",
    "        x = x + x_transform\n",
    "        \n",
    "        x = self.feed_forward(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits, None\n",
    "\n",
    "    def generate(self, idx, max_new_tokens, block_size, temperature=1.0):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self.forward(idx_cond)\n",
    "            \n",
    "            # Scale logits by the temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_new = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_new], dim=-1)\n",
    "        return idx\n",
    "\n",
    "# Hyperparameters\n",
    "block_size = 50  \n",
    "vocab_size = sp.get_piece_size()\n",
    "n_emb = 300\n",
    "n_layers = 5\n",
    "n_heads = 5\n",
    "dropout = 0.2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LanguageModel(vocab_size, n_emb, n_layers, n_heads, dropout).to(device)\n",
    "print(f'Number of parameters {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,” he shouted, “I am here. I climb! I haste! Ahuwora! The stones slip under my feet! Wait my coming, O most infamous Bandar-log!” He\n",
      ",” he shouted, “I am here. I climb! I haste! Ahuwora! The stones slip under my feet! Wait my coming, O most infamous Bandar-log!” He pan\n",
      "tensor([[  58,  106,   14, 1762,    3,   25,   65,  179,  250,    6,   16, 1329,\n",
      "           62,   16,  172,  235,   62,  153, 1572,  140,   94,   58,   62,   52,\n",
      "          830,    5, 1801,  354,   59,  605,   62,   15, 2728,   59,  724,    3,\n",
      "          388,  340,   11,  137,  262,  330,  247,  268,  109,   35,  213,   64,\n",
      "          190,   80]])\n",
      "tensor([[ 106,   14, 1762,    3,   25,   65,  179,  250,    6,   16, 1329,   62,\n",
      "           16,  172,  235,   62,  153, 1572,  140,   94,   58,   62,   52,  830,\n",
      "            5, 1801,  354,   59,  605,   62,   15, 2728,   59,  724,    3,  388,\n",
      "          340,   11,  137,  262,  330,  247,  268,  109,   35,  213,   64,  190,\n",
      "           80, 1588]])\n",
      "torch.Size([1, 50]) torch.Size([1, 50])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data, block_size, batch_size):\n",
    "    idx = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "a, b = get_batch(train_ids, block_size, 1)\n",
    "print(sp.decode(a[0].tolist()))\n",
    "print(sp.decode(b[0].tolist()))\n",
    "print(a)\n",
    "print(b)\n",
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training Loss: 4.4243621826171875\n",
      "Validation loss: 4.436643600463867\n",
      "Step: 100 Training Loss: 4.342253684997559\n",
      "Validation loss: 4.3875298500061035\n",
      "Step: 200 Training Loss: 4.455770492553711\n",
      "Validation loss: 4.432043075561523\n",
      "Step: 300 Training Loss: 4.305920124053955\n",
      "Validation loss: 4.467496871948242\n",
      "Step: 400 Training Loss: 4.281492710113525\n",
      "Validation loss: 4.453366279602051\n",
      "Step: 500 Training Loss: 4.447474479675293\n",
      "Validation loss: 4.499084949493408\n",
      "Step: 600 Training Loss: 4.390917778015137\n",
      "Validation loss: 4.3538312911987305\n",
      "Step: 700 Training Loss: 4.314742565155029\n",
      "Validation loss: 4.368034362792969\n",
      "Step: 800 Training Loss: 4.262165546417236\n",
      "Validation loss: 4.408949375152588\n",
      "Step: 900 Training Loss: 4.271276950836182\n",
      "Validation loss: 4.370126247406006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32\n",
    "early_stop = 20\n",
    "last_val_loss = 1e9\n",
    "n_epochs = 1000\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for steps in range(n_epochs):\n",
    "    model.train()\n",
    "    xb, yb = get_batch(train_ids, block_size, batch_size)\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 100 == 0:\n",
    "        print('Step:', steps, 'Training Loss:', loss.item())\n",
    "        val_loss = estimate_loss(model, val_ids, block_size, batch_size)\n",
    "        print('Validation loss:', val_loss)\n",
    "        if val_loss >= last_val_loss:\n",
    "            early_stop -= 1\n",
    "            if early_stop == 0:\n",
    "                print('Early stop!')\n",
    "                break\n",
    "        else:\n",
    "            early_stop = 10\n",
    "            last_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'datasets/text/good_cleaned_tales.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman had a little daughter might an hour humbles. They were transpreak for breakfast in his emotion and admate of the people as could as ancientd that climbed the first time during keep the work of the ship.” “And if it was extra very well, acquarable, struck, in the harpoon of the cases and eventle, it was Suart lunch red and village so much as your subjects might be active better to no food. Ingi, what I feel a change to make you, equally maternal Istinate work. I standing there for a house. He flew? “‘No lad, poor Equevo-turgling amongn Proll in Sapoaleer’s youth,? bear, and to missewaitable practices.  ⁇ aught here, Wan half anger-bell and carrying life. We’ve the Hereing of doover; it was scarcely uncomply there’mocks’ clean echohooded scolded Pips and needns yet since has such a seat was the suggestion of bubage mistake of his name. Though he says, every thing,” said hisrgic nap of character. “Rimbye,” she said, a surprise, ‘to apthis shot with that Indians to me! New York,” exclaimed Hucksion. “She is saved. “What in a bug children of Thump!” cried Mary; I sometimes wise, whose muest.. ‘Pray mean me we take myself joyfully as Exef. Doctor!\" he said, who said that who had passed, instant, while it seemed to look before with the dragon was satisfied a real sackless trees. ‘I am quite leake licked which I refused him familiar Ahab if that U God had lete threeed for to breaker had been welcomeables to bet any use, we scratch them. Remover I trustd a whombusing a alongeighool eyeable; gentlemen don’t I please itdokins for ye, you my path indeed, the soupience was being buried. I tell you set out prono, yesterday, dear ceive it. Was this! Not, you have broken me, Jo't done? An Mother, Mr. Lorry. I'm made the Wonde, but Fretttore was to well that you had it all, “Prob. Oh, not a very different last eventity of seven little voice, and let me have another key on a native sprang to the rest of bad acquaintance, and make pride often, any cause; you heard that occasiony, in rippic abrusance that of untoward, for the room hope, for I have the welcome of the processioned Greenkisd her. It was so much trying to use that good heart had a more expose and Cadmus lay a soft someone ringated in the matter. As we were treatable also had only been an immensed for her remordly failed Christmas her and waited, very little. He waited when the fox hat-peop was about to set some feast, vainly-bbling blackgerions of her cabin. “What he’s my kind little creemonial whaling maybe that Peake desquiston the King’s private distress. He seemed here anxious to eat us in he was, could be three to be a matter so adger, a sick man of anatingt that man on the house, wa, especially even on a room to staring. In a minute that things whenever had been the sparrow commanded the blood grace which two wearies were fast to the appearance of the stairs to the other Parodle. When him. Saint his mere was invited bins myself; he seemed to get his once more wild children. Parisless effort his emperi mesical fortune and on the village. Suddenly immediately Father spirit as he wept like feeling things, he turned to her as a hand, who was too old at one eye, and every one to death gave under Thor, said, because I was. As soon as I said to her tacks. I forgot it, only they sitting on her story, with threaking, Me When he was a leaves fairer neggerant into Singame mounted his dry table garden and helped Sudeler couldn't remind save his week. She was narrow still as his claws that every ulge tripse his keen matter hasity. He falling, and as if he have prexed his wide mure might to have a superry, and all those procious duakling. When he came to the wind, and take that brought he fell down in the hundredroom; he sang and impresses the arrow. In that imporded him his cordern to arrange the merivyeon and awoke, goldenly gave the fair-by consideration. Confii heard which not only whispering him that he walked that their Prince would laugh his brain, that were true. All found the small marvellictures and view, I found that parts it was together that before dui paid that a let. But the wood was extra-chury, having thitherderte with the rest of the day. My companion came back with his skill. He pulled it out, was  ⁇ aching this sowent and a tempus. His inglient compassion Dis LOS Mord. D  ⁇  Englishb. Presently a brother considerable brooked. “You cannot stay, as we dost thou understand flatter is; but you are a fresh opinion. At the poor prince was only thing generally for one of many affairs and that has none of these plenty. By I don't think I should never work, how I don't get to you to think real!” \"Leguite it?\" And when Jo left she sawd him that Tom'sland part of his vague attention a stick of his maid; and Laurie laid hisly pleased the way to marry a long, as if it was, had to executed. The walking roses passed in a claws below about for a Dancegarsons, and followed their main surroundts by; and every whale bewell to know the order khaguouscal prother.” And when they loved out of this odd old one end, the child saw that in a gratical loss where the man was in Moitation. Gree was seeking him. Hrozebandar Alock's good-cutthen despunted all I had vain to regazent sort of times, and tapped. Well, none of darkness, it would be this sobbones, should I shall still be emptal. But what do you perform careful?” asked Rogojin. “Sitation was,” Hans waxed at her with something quite satisfied. “I shall not seem to the least and cremen, too; others,” said I, “how Stubb think there are lovely propertys clear stripa of your noise ‘ sorry for her on the hill, habit along on the lonest; you or so Tom, my friend. Saphip me to asheke out of blood so much in the company, and the mark of each attempt to lead his existence life.” “Oh, dis minding?’ ‘OUsdeclour ofmation. “Here I'm name is fault,” I asked him not, for.. Saize a year on the bank and here. ‘That is very much the real time?” he asked. “Well,” he said, 'beliest with his son, “for my lifeant bit the room, where bidi no small right, don’t thou know, or Iund one knew and his age. I have been chosen’t o’ ground.” She was drank, keeping. But tell me, at last shoulder Other let me go to flieves, but their being a silver air, that I arrived like absurd, by the painful and chiefs. But he got to sit round the night barre soundless house. Just as they found in mentioning that the very King cried to himself, \"Godeep at position!\" and paused as got, curious-per continued, that if the little finger a fault was comchided. \"Pecon him, and I am not so nice, business because I can be so unusual to get over upon the King that there must be to my father, you are, so you shall criness prove up to know how Edward to someternal poor father as could you keep you an hour of one by means for which I see my raple sort, to all this cruel men.” “Yes, inasion to get his type.” “There is his right hand to me that lovely nest, talk. He has never adre of honeyial. The sharethia; I cannot have no needless sowles? And when I rose f\n"
     ]
    }
   ],
   "source": [
    "starting_tokens = 'A crazy dog'\n",
    "\n",
    "encoded_start = sp.encode(starting_tokens, out_type=int)\n",
    "len_starting_tokens = len(encoded_start)\n",
    "\n",
    "idx = torch.tensor(encoded_start).reshape(1, len_starting_tokens).to(device)\n",
    "generation = model.generate(idx, max_new_tokens=2000, block_size=block_size, temperature=2)[0].tolist()\n",
    "print(sp.decode(generation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A long time I felt what until you at?” She kept his eyes. no one knew he was at his hook; when she looked to her stood ready to her, he nodded like an oxes with guests to and snatch circilleping up into the matter. When she held it to see if she could not go very right, and then, however were more as feeling that, she journeyed unap to kill him to come. The whip married. The Woodman never went alone. Her grooms, and more the baby gloryors were at thought, when, it seemed an eightone was broad. Apany event ⁇  gods the world-hloth which a flight. Bey of mine! No one could see, who was off to perfect tricks, and one little sister. His chance was tired, for the loved block Holmes did not got ridable party were not lost, and recase and was ever gone forth. They raised an expression, but the boating heart which the big woman, as its friend, might ever be pulled? There were safe besides; the success were one of the skipcassagged protecting fairy. In a place, she found where a peculiar warm tower of one end on refreshment of switking under the verestontauce which followed by the water. They not held the Dogre of the solitary animal to the rest of the lim. They had called a poet of speaking supplet leaped one of us. “How must that lies at the goins; you have Wendy of Belly, because ever speaks at th’hes!” Then the little hill and little people very young more at Nabumps. All the folded leather a!’ Deirdissure to land. \n",
    "\n",
    "“It was a strong baby company I following in?” said he, Prince A’ha neighbor. “Boul I read Shere Khans. Wight Lorda’ such an ane Fagoo and boat in thee fenceber dollars should men of a lane, an’ my children, and’m all three his yodtos; thinking I do so, prince, stupid amissed pictures. How are Naggigous than about it!” he stood coming out So they made him, but he said, “I shall never tell wife, it doesn't tell another how prince, it is to have it? It isn't that I'm answer blossom. There's my darlinger. It once Two ’board is as delicate.’ And if the shadow looked to forgive and see,” said Holmes and his famreyed. “Not now, sir.” Then she talked for the drifted him, but no one had many executed him to make the packial forew off his amazement. For put the generally standing down a laugh. He was under his payment to blows, a soapdern, and but it was needleting more the wife, was giving as to say him, but darting Peleg the cases But with those that it gave how their tipl those things. It was taken a parts, and his horror there stood a big wail and powerfully ervention of his nose his supper. Jack said, \"Don't since know, very well. He said, didn’t you well; what is a good deal that he was the always of this!” “Ah! how you know.” “Don't you think that?” cried the tailor, “come just particularly put, or she is so honest an’press mad so heattering you. So he said he would not give the meant it again to Willoughby,” and we were all the end or his wife. “Well! Now thou did Pell bring me in the other’ will wig,” she returned the little good surprise, “there reckinger his lamp into a ring, from the least in the same time in all. I found a man of pantuffence, looks as well. It shall you throw on one finger the evening I comehead into which you know? Jalopthinally a day.” “To somebodyrog a idea that now? How in beciments; brother you think no heds with more pretty right profather could neither. Come out of any one,” added Tom he was decided to go the perfect article-sedood at the room. “Lhu ditt hand. and no! Boc, thou does you think; it knows anyone who well who is.” “Oh. Lebedeff’s concern,” continued his sword. Rogojin sent her chame consolated stream in a fawn-blaked one hundred who come, and it was the notion of the death of his squid with satisfactions, but which promises a real lurch ⁇  OLDe the him followed whaling, purpose all was never to find outn,' and told him him that, then take them to his countenance. \"Dam’t search my taste eagerly foot, don't you had You are very handsome and it Do you take a subject for everything a hundred that if flocks off my spurdy, I thought that the explanation is not so much brighter than you have comes when our miserable.” The very corate, and to disrere enough and breaked them. “Be your mother this fact, I Ccuse concerned Silver they reached a glow. Why don't you know ever lay at any depiience. D a sick wedding Jon. When you still was always at you and bare, and to have started up an Throdd frock of business  ⁇  at the mark, Amon her account of having a nought ane canal haste them to the sea, fond of mine that wouldn’t useful; for if one cannot be more torgle you for your enemy' an alone; there suddenly they will examin no payments, there reigns-bable and practto from that?” “What you are such a wonderful anything about them,There might break you can become true for the nurse with much dark. ⁇ . “ billain society had tempestly relief, pumbit brantal it was he held feet, next fairy manner of snation had one hand. ‘Look,” said Ivan Plastuldsman. ‘Thank you of an illority, madame.” 'Let we are very difficulter, about him that of mere scene pereducable revernive silver I’ll keep your cabin young tramp. That means one thing for everything have been right, a small crast now?” asked Mrs. Jac, “I thought it is, by the chrecier people and my hunting wife, Tom.” And God now they both spend full of golden bathis, trees the water, but lived a held, and stood quite polite, but lock. Gran streamij for the creame face for me, fair and drows into my young prince in the darkness of the Jungicized country nests.” kneeillished with king, with still quite tightness. When thrie humor, holy as soon as may be just any ill-ra, has entered singing forbid in his spees,” said to the money. “Who is the same general. I am the use of counseles’ glasser again,” said Hippolyte, “you was not like vained.” But there was there intuning they had not made one thing to lose this; but she wanted to do it.” Then he got actually up his talk to his tail, and half and taking out just to step him before his self-gnight, perhaps, co,” twented it, and there with each other. “It was shames been turned to tell us,” said the Lione with him. “To it was an earthotes had been broken him well with a sort of brionout Th!” “Wack-for I grant meat side work for me?” “You tell just the same matter being out,” Mary shouted, “thater?” The prince remembered th’ talk. “I am Stubb.” “That’s something,” said the foot, “thising a rise or approach-beby,” said little. “Good-ventish brown whisker against the other orders.\" \"Where must be happening?\" said the Test Warncy pubtegentities. \"Bet dishettle,\" says the one of their London, \"hils fighting anything, barrel regarding down. Takeing me in spite of it boys. Even.\" And  ⁇ E. The Staysan Jane might be at the herocy Dand a countenance. \"The Has blew the Sultan's account, he remarked mi savedious that we was not Little Impusive on the seaugh of wood whale blind quarters, which would be so warniable power of French occasion under flame, and then she pleased. George Cretumilnaine put her a broad hand, and severaled the adm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
