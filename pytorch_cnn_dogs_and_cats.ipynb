{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfS_DZfV_n9o",
        "outputId": "6d13af45-57f6-4212-9c4d-65de5cb9b0e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets/dog_and_cat/training_set/training_set/cats\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4001 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4001/4001 [00:02<00:00, 1597.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets/dog_and_cat/test_set/test_set/cats\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1012/1012 [00:00<00:00, 1581.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets/dog_and_cat/training_set/training_set/dogs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4006/4006 [00:02<00:00, 1493.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datasets/dog_and_cat/test_set/test_set/dogs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1013/1013 [00:00<00:00, 1499.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat count: 4000, dog count: 4005\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "REBUILD_DATA = True\n",
        "CAT = 'datasets/dog_and_cat/training_set/training_set/cats'\n",
        "DOG = 'datasets/dog_and_cat/training_set/training_set/dogs'\n",
        "CAT_TEST = 'datasets/dog_and_cat/test_set/test_set/cats'\n",
        "DOG_TEST = 'datasets/dog_and_cat/test_set/test_set/dogs'\n",
        "SAVE_FILE = 'datasets/dog_and_cat/data_cat_dog_processed.npy'\n",
        "LABELS = {CAT: 0, CAT_TEST: 0, DOG: 1, DOG_TEST: 1}\n",
        "IMG_SIZE = 64\n",
        "\n",
        "class DogvsCat():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.data = []\n",
        "    self.cat_count = 0\n",
        "    self.dog_count = 0\n",
        "\n",
        "  def make_training_data(self):\n",
        "    for label in LABELS:\n",
        "      print(label)\n",
        "      for f in tqdm(os.listdir(label)):\n",
        "        if 'jpg' in f:\n",
        "          path = os.path.join(label, f)\n",
        "          img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "          img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "          self.data.append([np.array(img), LABELS[label]])\n",
        "          if label == CAT:\n",
        "            self.cat_count += 1\n",
        "          if label == DOG:\n",
        "            self.dog_count += 1\n",
        "\n",
        "    np.random.shuffle(self.data)\n",
        "    np.save(SAVE_FILE, self.data)\n",
        "    print(f'cat count: {self.cat_count}, dog count: {self.dog_count}')\n",
        "\n",
        "if REBUILD_DATA:\n",
        "  dogvscat = DogvsCat()\n",
        "  dogvscat.make_training_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8022, 1, 64, 64]) torch.Size([8022]) torch.Size([2006, 1, 64, 64]) torch.Size([2006])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = np.load(SAVE_FILE, allow_pickle=True)\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "X_train = torch.Tensor([i[0] for i in train]).view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
        "y_train = torch.Tensor([i[1] for i in train])\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "X_test = torch.Tensor([i[0] for i in test]).view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
        "y_test = torch.Tensor([i[1] for i in test])\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "X_train, X_test = X_train/255.0, X_test/255.0\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "muesiAWEPRgz"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=4, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(128*15*15, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = x.view(-1, 128*15*15)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (fc1): Linear(in_features=4608, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/251 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 253.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 0.6189684867858887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 295.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 0.6166988015174866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 286.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, loss: 0.5685239434242249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 293.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, loss: 0.47609108686447144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 297.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, loss: 0.44071969389915466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 292.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, loss: 0.45303142070770264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 295.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, loss: 0.4704507887363434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 299.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, loss: 0.43930405378341675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 297.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, loss: 0.4882688522338867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 297.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, loss: 0.2786512076854706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 301.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, loss: 0.08650144934654236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 290.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, loss: 0.10509545356035233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 292.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, loss: 0.15935851633548737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 302.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13, loss: 0.056599196046590805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 300.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14, loss: 0.0030650226399302483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 287.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15, loss: 0.12244001030921936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 287.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16, loss: 0.03829025849699974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 288.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17, loss: 0.010456277057528496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 294.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18, loss: 0.16468463838100433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 251/251 [00:00<00:00, 292.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19, loss: 0.027447042986750603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "print(net)\n",
        "net.zero_grad()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for data in tqdm(train_data_loader):\n",
        "    X, y = data\n",
        "    y = y.long()\n",
        "    net.zero_grad()\n",
        "    output = net(X)\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'Epoch: {epoch}, loss: {loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.764\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for data in test_data_loader:\n",
        "    X, y = data\n",
        "    y = y.long()\n",
        "    output = net(X)\n",
        "    for idx, i in enumerate(output):\n",
        "      if torch.argmax(i) == y[idx]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "  print(f'Accuracy: {round(correct/total, 3)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
