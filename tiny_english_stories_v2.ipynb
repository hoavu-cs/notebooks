{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoavu-cs/notebooks/blob/main/tiny_english_stories_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9pHCodg4zzxu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pickle\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "from tokenizers import ByteLevelBPETokenizer, processors\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1qJAVbOe196m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108defe6-a524-4f56-af0d-57e1e3157a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-qVyof2BgJ",
        "outputId": "d1a3b84d-a2f2-4161-bdbf-8d73393aa561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " english_tiny_stories_18m.pth\t      english_tiny_stories_4layers.pth\n",
            " english_tiny_stories_28m.pth\t      english_tiny_stories.pth\n",
            "'english_tiny_stories_2 - Copy.pth'   merges.txt\n",
            " english_tiny_stories_2.pth\t      TinyStoriesV2-GPT4-train.txt\n",
            " english_tiny_stories_37m.pth\t      TinyStoriesV2-GPT4-valid.txt\n",
            " english_tiny_stories_4layers_2.pth   vocab.json\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n",
        "data_path = \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'TinyStoriesV2-GPT4-train.txt'\n",
        "val_filename = 'TinyStoriesV2-GPT4-valid.txt'\n",
        "\n",
        "filepath = os.path.join(data_path, filename)\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    train_data = file.read()\n",
        "train_data = train_data.replace('\\n', '')\n",
        "train_data = train_data.split('<|endoftext|>')\n",
        "\n",
        "val_filepath = os.path.join(data_path, val_filename)\n",
        "with open(val_filepath, 'r', encoding='utf-8') as file:\n",
        "    val_data = file.read()\n",
        "val_data = val_data.replace('\\n', '')\n",
        "val_data = val_data.split('<|endoftext|>')\n",
        "\n",
        "print(train_data[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ6Gsjjjqi4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaa28d0-3398-452a-d160-2b2ab90da8fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.DataFrame(train_data, columns=['content'])\n",
        "val_data = pd.DataFrame(val_data, columns=['content'])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "\n",
        "print(train_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB6DsNYWK6Gr",
        "outputId": "e8d75778-428d-4277-880a-aabebd7381ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2717700, 1)\n",
            "(27631, 1)\n",
            "                                             content\n",
            "0  Once upon a time there was a little boy named ...\n",
            "1  Once upon a time, there was a reliable otter n...\n",
            "2  One day, a little boy named Tim went to the pa...\n",
            "3  Once upon a time there was a friendly little b...\n",
            "4  Once upon a time, in a small house, there live...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "tokenizer.train(files=[os.path.join(data_path, 'TinyStoriesV2-GPT4-valid.txt')], vocab_size=10000, min_frequency=1, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "tokenizer.save_model(data_path)"
      ],
      "metadata": {
        "id": "1VFv6VYZrenp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9cd9fa-93a0-4931-9192-a28f80e1de5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/datasets/NLP/tiny_stories/vocab.json',\n",
              " '/content/drive/My Drive/datasets/NLP/tiny_stories/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_path = os.path.join(data_path, \"vocab.json\")\n",
        "merge_path = os.path.join(data_path, \"merges.txt\")\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    vocab=vocab_path,\n",
        "    merges=merge_path\n",
        ")\n",
        "\n",
        "tokenizer.add_special_tokens([\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "\n",
        "tokenizer._tokenizer.post_processor = processors.BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VOXL-GXxr2Oq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Encode a text string\n",
        "print(train_data.loc[0, 'content'])\n",
        "output = tokenizer.encode(train_data.loc[0, 'content']).ids\n",
        "print(\"Decoded string: \", tokenizer.decode(output, skip_special_tokens=False))  # decoding back to the original string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLmGXW9Usx3v",
        "outputId": "912824e2-b367-4b2a-dabc-0ab8692555e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n",
            "Decoded string:  <s>Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yQ9D6gFazzxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fba751-88f8-4bce-d5ac-bacef625b8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is  10000\n"
          ]
        }
      ],
      "source": [
        "BLOCK_SIZE = 256\n",
        "VOCAB_SIZE = len(tokenizer.get_vocab())\n",
        "print('Vocab size is ', VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eot_id = tokenizer.token_to_id(\"<|endoftext|>\")\n",
        "start_id = tokenizer.token_to_id(\"<s>\")\n",
        "end_id = tokenizer.token_to_id(\"</s>\")\n",
        "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
        "unk_id = tokenizer.token_to_id(\"<unk>\")"
      ],
      "metadata": {
        "id": "A17FtD1XtLx0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMAvqIY8zzxw",
        "outputId": "3c9d7feb-712f-4692-fcde-fe64e2115776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256]) torch.Size([1, 256])\n",
            "<s>Once upon a time, there was a friendly cat named Tom. Tom loved to watch the parade in his town. He would see big floats, loud music, and happy people. Tom wanted to be a part of the parade too.One day, Tom found a magic button. The button could make things shrink. Tom had a big idea! He thought, \"If I shrink the big floats, I can be in the parade too!\" So, he pushed the button and all the big floats became small.Now, Tom and his small floats joined the parade. Everyone loved the small floats and Tom was so happy. The friendly cat and the small floats made the parade even more fun. And from that day on, Tom and his small floats were always a part of the parade.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Once upon a time, there was a friendly cat named Tom. Tom loved to watch the parade in his town. He would see big floats, loud music, and happy people. Tom wanted to be a part of the parade too.One day, Tom found a magic button. The button could make things shrink. Tom had a big idea! He thought, \"If I shrink the big floats, I can be in the parade too!\" So, he pushed the button and all the big floats became small.Now, Tom and his small floats joined the parade. Everyone loved the small floats and Tom was so happy. The friendly cat and the small floats made the parade even more fun. And from that day on, Tom and his small floats were always a part of the parade.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "def get_batch(data, block_size, batch_size):\n",
        "    x = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    y = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    samples = data['content'].sample(n=batch_size)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        summary_ids = tokenizer.encode(sample).ids\n",
        "        #summary_ids = [id for id in summary_ids if id != UNK_ID]\n",
        "        if len(summary_ids) < block_size + 2:\n",
        "            summary_ids = summary_ids + [pad_id] * (block_size + 2 - len(summary_ids))\n",
        "        random_start = random.randint(0, len(summary_ids) - block_size - 2)\n",
        "        x[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start:random_start + block_size], dtype=torch.long)\n",
        "        y[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start + 1:random_start + block_size + 1], dtype=torch.long)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "a, b = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=1)\n",
        "print(a.shape, b.shape)\n",
        "print(tokenizer.decode(a[0].tolist(), skip_special_tokens=False))\n",
        "print(tokenizer.decode(b[0].tolist(), skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model  # delete the tensor variable\n",
        "torch.cuda.empty_cache()  # clear unused memory in PyTorch\n",
        "gc.collect()  # call Python garbage collector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQJerzes3nvz",
        "outputId": "07ca648b-757d-4d63-a6a9-ccf86e0f72a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "583"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnsjYq0jzzxw",
        "outputId": "d1d06374-3bbc-4bb7-9511-71db1c180416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters 84357792\n"
          ]
        }
      ],
      "source": [
        "N_EMB = 1200\n",
        "N_LAYERS = 4\n",
        "N_HEADS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "\n",
        "def estimate_loss(model, val_data, block_size, batch_size):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, y = get_batch(val_data, block_size, batch_size)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        _, loss = model(x, y)\n",
        "    model.train()\n",
        "    return loss.item()\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.tril(torch.ones(sz, sz)) == 1).float()\n",
        "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def get_sine_position_encodings(length, dim):\n",
        "    pos = torch.arange(length, dtype=torch.float32).reshape(-1, 1)\n",
        "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(math.log(10000.0) / dim))\n",
        "    pos_encodings = torch.zeros(length, dim)\n",
        "    pos_encodings[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pos_encodings[:, 1::2] = torch.cos(pos * div_term)\n",
        "    return pos_encodings\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, n_emb, block_size, n_layers, n_heads, dropout=0.2):\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=n_emb, nhead=n_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(n_emb, 6 * n_emb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6 * n_emb, n_emb)\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        token_emb = self.token_embedding_table(idx)\n",
        "        position_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "\n",
        "        x = token_emb + position_emb\n",
        "        x_transform = x.clone()\n",
        "        mask = generate_square_subsequent_mask(T).to(device)\n",
        "\n",
        "        x_transform = self.transformer_encoder(x_transform.permute(1, 0, 2), mask=mask)\n",
        "        x_transform = x_transform.permute(1, 0, 2)\n",
        "        x = x + x_transform\n",
        "\n",
        "        x = self.feed_forward(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            return logits, None\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, block_size, temperature=1.0, stop_token=False):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self.forward(idx_cond)\n",
        "\n",
        "            # Scale logits by the temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_new = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat([idx, idx_new], dim=-1)\n",
        "            if stop_token and idx_new.item() == end_id:\n",
        "                break\n",
        "        return idx\n",
        "\n",
        "# Create model, optimizer\n",
        "model = LanguageModel(vocab_size=VOCAB_SIZE, block_size=BLOCK_SIZE, n_emb=N_EMB, n_layers=N_LAYERS, \\\n",
        "    n_heads=N_HEADS, dropout=DROPOUT).to(device)\n",
        "\n",
        "print(f'Number of parameters {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5d8MVV6Azzxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a59843-de29-4e6a-9391-c59a7683029a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/datasets/NLP/tiny_stories/english_tiny_stories_4layers.pth\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers.pth\")\n",
        "print(model_path)\n",
        "model = torch.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKRlCdwgzzxy",
        "outputId": "15d4e4a8-6f0e-42b5-f3a7-965608fe6e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 Training Loss: 1.2919141054153442\n",
            "Validation loss: 1.0863735675811768\n",
            "Step: 100 Training Loss: 1.2361135482788086\n",
            "Validation loss: 1.4048341512680054\n",
            "Step: 200 Training Loss: 1.1905324459075928\n",
            "Validation loss: 1.212174892425537\n",
            "Step: 300 Training Loss: 1.194663166999817\n",
            "Validation loss: 1.1724224090576172\n",
            "Step: 400 Training Loss: 1.241074562072754\n",
            "Validation loss: 1.1256732940673828\n",
            "Step: 500 Training Loss: 1.284751057624817\n",
            "Validation loss: 1.148874282836914\n",
            "Step: 600 Training Loss: 1.2424288988113403\n",
            "Validation loss: 1.2228186130523682\n",
            "Step: 700 Training Loss: 1.219326376914978\n",
            "Validation loss: 1.1170852184295654\n",
            "Step: 800 Training Loss: 1.3331797122955322\n",
            "Validation loss: 1.1689926385879517\n",
            "Step: 900 Training Loss: 1.21454918384552\n",
            "Validation loss: 1.2301558256149292\n",
            "Step: 1000 Training Loss: 1.4424545764923096\n",
            "Validation loss: 1.3047943115234375\n",
            "Step: 1100 Training Loss: 1.245028018951416\n",
            "Validation loss: 1.213889479637146\n",
            "Step: 1200 Training Loss: 1.2754627466201782\n",
            "Validation loss: 1.1935557126998901\n",
            "Step: 1300 Training Loss: 1.3432105779647827\n",
            "Validation loss: 1.0803929567337036\n",
            "Step: 1400 Training Loss: 1.2548093795776367\n",
            "Validation loss: 1.2505805492401123\n",
            "Step: 1500 Training Loss: 1.1544499397277832\n",
            "Validation loss: 1.1671196222305298\n",
            "Step: 1600 Training Loss: 1.2611125707626343\n",
            "Validation loss: 1.2770965099334717\n",
            "Step: 1700 Training Loss: 1.1968331336975098\n",
            "Validation loss: 1.1723535060882568\n",
            "Step: 1800 Training Loss: 1.2502175569534302\n",
            "Validation loss: 1.3108758926391602\n",
            "Step: 1900 Training Loss: 1.391462802886963\n",
            "Validation loss: 1.262884497642517\n",
            "Step: 2000 Training Loss: 1.156810998916626\n",
            "Validation loss: 1.2461655139923096\n",
            "Step: 2100 Training Loss: 1.433143138885498\n",
            "Validation loss: 1.291175365447998\n",
            "Step: 2200 Training Loss: 1.4573324918746948\n",
            "Validation loss: 1.3680388927459717\n",
            "Step: 2300 Training Loss: 1.1937731504440308\n",
            "Validation loss: 1.2105605602264404\n",
            "Step: 2400 Training Loss: 1.2704898118972778\n",
            "Validation loss: 1.1132593154907227\n",
            "Step: 2500 Training Loss: 1.3124957084655762\n",
            "Validation loss: 1.1811915636062622\n",
            "Step: 2600 Training Loss: 1.250178337097168\n",
            "Validation loss: 1.0770236253738403\n",
            "Step: 2700 Training Loss: 1.2297848463058472\n",
            "Validation loss: 1.091646671295166\n",
            "Step: 2800 Training Loss: 1.2429437637329102\n",
            "Validation loss: 1.1449699401855469\n",
            "Step: 2900 Training Loss: 1.292833685874939\n",
            "Validation loss: 1.2810181379318237\n"
          ]
        }
      ],
      "source": [
        "EARLY_STOP = 50\n",
        "N_EPOCHS = 3000\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "last_val_loss = 1e9\n",
        "early_stop = EARLY_STOP\n",
        "\n",
        "for steps in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    xb, yb = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Delete xb, yb and free GPU memory\n",
        "    del xb, yb\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if steps % 100 == 0:\n",
        "        print('Step:', steps, 'Training Loss:', loss.item())\n",
        "        val_loss = estimate_loss(model, val_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "        print('Validation loss:', val_loss)\n",
        "        # if val_loss >= last_val_loss:\n",
        "        #     early_stop -= 1\n",
        "        #     if early_stop == 0:\n",
        "        #         print('Early stop!')\n",
        "        #         break\n",
        "        # else:\n",
        "        #     early_stop = EARLY_STOP\n",
        "        #     last_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh2aOVX1zzxy"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers_2.pth\")\n",
        "torch.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCZ8RJ-zzxz",
        "outputId": "a2ec9aa9-7299-4de7-e87c-9936ff31bbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story  1 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. Suddenly, she heard a voice. It was a little girl.Alice ran over to the girl. She saw a small bird now. The bird was lost and could not find its mom.Alice was very sad. She said, \"Hi, bird! Are you lost? Can you help me find my mom?\"The bird looked at Alice and said, \"Yes, I will help you. Let's look for your mom together.\"Alice and the bird walked together and found her mom's mom. The mom was very happy. Alice was happy too. She said, \"Thank you, bird! You are a great friend.\"\n",
            "\n",
            "\n",
            "Story  2 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She suddenly felt helpless. She did not know what to do. Suddenly, she heard a loud noise.Alice turned around and saw a big dog. The dog was hungry and wanted to eat it.Alice was scared. She wanted to run away, but the dog did not run away. She slowly walked towards the dog. The dog saw her and wanted to eat her. Alice was happy. She ran back to the dog and gave the dog a big hug. The dog did not eat her chicken. They became friends and played together for the rest of the day.\n",
            "\n",
            "\n",
            "Story  3 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. Alice was sad. She asked her mom, \"Why is my chicken so dark?\" Her mom said, \"Because it's dark.\"Alice was sad. She decided to go back and explore. She threw her chicken in the sky. Then, something magical happened! Alice's mom had an idea. She said, \"Let's send a new chicken to our new chicken. The chicken will come on something fun!\"Alice was so happy. She went and enjoyed the new chicken together. She was no longer scared. She knew her mom would love the chicken too.\n",
            "\n",
            "\n",
            "Story  4 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not find it.Alice was very tired. She decided to go and relax. She decided to take a break.Alice searched all around but she couldn't find it. Finally, she saw a little boy with her chicken.Alice was eating a bike with a big smile on his face.Alice had a red bike and a blue bike. She was curious and decided to ride it.Alice was so happy to have a waffle. She rode around the park and it felt wonderful!Alice and the little boy went on the swings and slides. They played together for a long time. Alice was so tired, but happy to have found the chicken. She knew she had found her chicken.Alice waved goodbye to the little boy and went to her mom. She told her mom, \"Mom, I am so glad you loved it!\" Her mom smiled and praised her. She hugged Alice and said, \"I love you, Alice.\" Alice smiled and nodded. She was glad she could help the little boy. She was a clever girl.\n",
            "\n",
            "\n",
            "Story  5 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She felt scared. She missed her friends and the flowers. She did not know where she was.She looked around and saw a big tree. She walked to it and saw a bench. She was so happy!She climbed down the tree and reached for the chicken. But she was scared. She cried and cried. She wished she had listened. But no one came.Alice was lost and scared. She cried and ran back to her mom. She called for help, but no one came. Her mom and dad could not hear her. She was very sad and scared. She never saw her chicken again.\n",
            "\n",
            "\n",
            "Story  6 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She looked everywhere for it, but the chicken just couldn't find it. Then, she spotted it was the chicken.Alice and her mom were so happy! They wanted to find the chicken.Alice and her mom walked around the world. Alice saw a big dog with a big smile. She stopped and tried to pet the chicken. But the chicken was too fast. It started to growl. Alice was scared. She did not know what to do.Then, Alice saw a nice man. He was kind. He had something in his hand. Alice was happy. She went closer to the dog and said, \"Hi! My name is Alice. What is your name?\"The kind man nodded. He said, \"My name is Mary. What is your name?\"Alice said, \"My name is Polly. I am lost in the dark.\"The friendly man said, \"My name is Alice. You are a very nice girl. I'm here to help you.\"Alice smiled. She said, \"I'm the best May I have ever seen.\" Alice was happy. She was so happy. She and Ellie became friends. She was a good child. She made many new friends.\n",
            "\n",
            "\n",
            "Story  7 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She saw a tree with a big hole in it.Alice was scared. She asked the tree, \"Why are you there so dark?\" The tree said, \"I am in a dangerous hole. I cannot find my chicken.\"Alice was sad. She asked the tree, \"Why is the tree so dangerous?\" The tree said, \"I cannot find my chicken. I cannot get it.\"Alice was sad. She asked the tree, \"Do you know where my chicken is?\" The tree said, \"It's a swan. It's scared of there. It won't find it.\"Alice and the tree played in the dangerous hole. They were happy again.\n",
            "\n",
            "\n",
            "Story  8 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not find it.She searched and searched, but she could not find it. Until one day, Alice saw a swing. She was excited. She jumped up and took a leap, but the tie was too far away. Alice was confused. She called out, \"Where is my chicken?\"But her mom came and said, \"Alice, where are you going?\"Alice was very sad. She wanted to go back to the swing. As she looked, she saw her mom on the swing. Alice was so sad.She shouted, \"That was scary!\"But then, Alice heard her mom. \"Alice! You should not play with my chicken in the dark. She is curious.\"Alice felt bad. She knew she had to be careful. She said, \"I'm sorry, mom.\" Her mom hugged her and said, \"It's okay, Alice. We can get it back.\"Alice said, \"Yes, mom. I love you, mom.\"\n",
            "\n",
            "\n",
            "Story  9 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to panic. She started to cry in her room as she looked around, but it was nowhere to be found.Suddenly, Alice heard a voice. It was a friendly voice. \"Hey, Alice, where are you?\"Alice was so surprised. The voice belonged to a kind old man. \"My name is Mrs. Smith. Do you belong here?\"Alice nodded. The old man was so happy to have a new friend. They played together all the time. Alice was so happy, she hugged Mrs. Smith and thanked Mrs. Smith for her help. The old man smiled and said, \"You're welcome, Alice. I'm glad you came here. You are a good friend.\" Alice smiled and said, \"I love you, Mrs. Smith. You are the best garden ever!\" The old man said goodbye and Alice felt very happy. She thanked Mrs. Smith for helping her get through the dark.\n",
            "\n",
            "\n",
            "Story  10 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. Suddenly, Alice heard a noise. It was a little bunny. It looked at Alice and said, \"Why are you so scared?\"Alice said, \"I lost my chicken in the dark. I can't find it.\"The bunny said, \"I know where it is! Follow me!\"Alice followed the bunny, but then she saw a big, dark shadow. It was coming from the dark and it was so big!Alice was so scared to hear it. She tried to open it. But it was too heavy. She could not open it. Alice was stuck in the dark hole and could not get out. The bunny was still in the dark hole forever.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "starting_tokens = 'Alice lost her chicken. She went outside to look for it. But it was dark.'\n",
        "\n",
        "encoded_start = tokenizer.encode(starting_tokens).ids\n",
        "encoded_start.pop(-1)\n",
        "len_starting_tokens = len(encoded_start)\n",
        "\n",
        "idx = torch.tensor(encoded_start).reshape(1, len_starting_tokens).to(device)\n",
        "model.eval()\n",
        "N_SAMPLES = 10\n",
        "for _ in range(N_SAMPLES):\n",
        "    generation = model.generate(idx, max_new_tokens=1000, block_size=BLOCK_SIZE, temperature=0.7, stop_token=True)[0].tolist()\n",
        "    story = tokenizer.decode(generation, skip_special_tokens=True)\n",
        "\n",
        "    print('Story ', _ + 1, ':')\n",
        "    print(story)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}