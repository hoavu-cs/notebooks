{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoavu-cs/notebooks/blob/main/tiny_english_stories_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9pHCodg4zzxu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pickle\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "from tokenizers import ByteLevelBPETokenizer, processors\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1qJAVbOe196m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93c9ad7-0d30-4117-8c67-e7a47eff118b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-qVyof2BgJ",
        "outputId": "ea34e5d7-3fc0-4262-94ac-7d050f526540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " english_tiny_stories_18m.pth\t      english_tiny_stories.pth\n",
            " english_tiny_stories_28m.pth\t      merges.txt\n",
            "'english_tiny_stories_2 - Copy.pth'   TinyStoriesV2-GPT4-train.txt\n",
            " english_tiny_stories_2.pth\t      TinyStoriesV2-GPT4-valid.txt\n",
            " english_tiny_stories_37m.pth\t      vocab.json\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n",
        "data_path = \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'TinyStoriesV2-GPT4-train.txt'\n",
        "val_filename = 'TinyStoriesV2-GPT4-valid.txt'\n",
        "\n",
        "filepath = os.path.join(data_path, filename)\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    train_data = file.read()\n",
        "train_data = train_data.replace('\\n', '')\n",
        "train_data = train_data.split('<|endoftext|>')\n",
        "\n",
        "val_filepath = os.path.join(data_path, val_filename)\n",
        "with open(val_filepath, 'r', encoding='utf-8') as file:\n",
        "    val_data = file.read()\n",
        "val_data = val_data.replace('\\n', '')\n",
        "val_data = val_data.split('<|endoftext|>')\n",
        "\n",
        "print(train_data[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ6Gsjjjqi4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8901e2-8dbe-435f-b507-9a3bfd116ad8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.DataFrame(train_data, columns=['content'])\n",
        "val_data = pd.DataFrame(val_data, columns=['content'])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "\n",
        "print(train_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB6DsNYWK6Gr",
        "outputId": "39641e5f-1cdb-4bce-900e-9cbf15783b80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2717700, 1)\n",
            "(27631, 1)\n",
            "                                             content\n",
            "0  Once upon a time there was a little boy named ...\n",
            "1  Once upon a time, there was a reliable otter n...\n",
            "2  One day, a little boy named Tim went to the pa...\n",
            "3  Once upon a time there was a friendly little b...\n",
            "4  Once upon a time, in a small house, there live...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "tokenizer.train(files=[os.path.join(data_path, 'TinyStoriesV2-GPT4-valid.txt')], vocab_size=10000, min_frequency=1, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "tokenizer.save_model(data_path)"
      ],
      "metadata": {
        "id": "1VFv6VYZrenp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a9cd9fa-93a0-4931-9192-a28f80e1de5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/datasets/NLP/tiny_stories/vocab.json',\n",
              " '/content/drive/My Drive/datasets/NLP/tiny_stories/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_path = os.path.join(data_path, \"vocab.json\")\n",
        "merge_path = os.path.join(data_path, \"merges.txt\")\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    vocab=vocab_path,\n",
        "    merges=merge_path\n",
        ")\n",
        "\n",
        "tokenizer.add_special_tokens([\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "\n",
        "tokenizer._tokenizer.post_processor = processors.BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VOXL-GXxr2Oq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Encode a text string\n",
        "print(train_data.loc[0, 'content'])\n",
        "output = tokenizer.encode(train_data.loc[0, 'content']).ids\n",
        "print(\"Decoded string: \", tokenizer.decode(output, skip_special_tokens=False))  # decoding back to the original string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLmGXW9Usx3v",
        "outputId": "912824e2-b367-4b2a-dabc-0ab8692555e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n",
            "Decoded string:  <s>Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yQ9D6gFazzxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64922809-4f14-4400-957a-d2a8fc8cd8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is  10000\n"
          ]
        }
      ],
      "source": [
        "BLOCK_SIZE = 256\n",
        "VOCAB_SIZE = len(tokenizer.get_vocab())\n",
        "print('Vocab size is ', VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eot_id = tokenizer.token_to_id(\"<|endoftext|>\")\n",
        "start_id = tokenizer.token_to_id(\"<s>\")\n",
        "end_id = tokenizer.token_to_id(\"</s>\")\n",
        "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
        "unk_id = tokenizer.token_to_id(\"<unk>\")"
      ],
      "metadata": {
        "id": "A17FtD1XtLx0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMAvqIY8zzxw",
        "outputId": "cc278450-f61e-47a7-fbe7-82d307ff5c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256]) torch.Size([1, 256])\n",
            "<s>Once upon a time, in a small town, there was a cool cat named Tom. Tom loved to try new things. One day, he saw a tree and wanted to climb it.Tom said to his friend, the dog, \"I want to try to climb that tree. Can you help me?\" The dog said, \"Yes, I can help. Let's try together.\"They tried to climb the tree, but it was hard. Tom and the dog did not give up. They tried again and again. At last, they reached the top of the tree.The result was that they could see the whole town from the top of the tree. They were so happy. Tom said, \"We did it, friend! Thank you for helping me try.\"After that, Tom and the dog always tried new things together. They had lots of fun and were the best of friends.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Once upon a time, in a small town, there was a cool cat named Tom. Tom loved to try new things. One day, he saw a tree and wanted to climb it.Tom said to his friend, the dog, \"I want to try to climb that tree. Can you help me?\" The dog said, \"Yes, I can help. Let's try together.\"They tried to climb the tree, but it was hard. Tom and the dog did not give up. They tried again and again. At last, they reached the top of the tree.The result was that they could see the whole town from the top of the tree. They were so happy. Tom said, \"We did it, friend! Thank you for helping me try.\"After that, Tom and the dog always tried new things together. They had lots of fun and were the best of friends.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "def get_batch(data, block_size, batch_size):\n",
        "    x = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    y = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    samples = data['content'].sample(n=batch_size)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        summary_ids = tokenizer.encode(sample).ids\n",
        "        #summary_ids = [id for id in summary_ids if id != UNK_ID]\n",
        "        if len(summary_ids) < block_size + 2:\n",
        "            summary_ids = summary_ids + [pad_id] * (block_size + 2 - len(summary_ids))\n",
        "        random_start = random.randint(0, len(summary_ids) - block_size - 2)\n",
        "        x[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start:random_start + block_size], dtype=torch.long)\n",
        "        y[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start + 1:random_start + block_size + 1], dtype=torch.long)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "a, b = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=1)\n",
        "print(a.shape, b.shape)\n",
        "print(tokenizer.decode(a[0].tolist(), skip_special_tokens=False))\n",
        "print(tokenizer.decode(b[0].tolist(), skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model  # delete the tensor variable\n",
        "torch.cuda.empty_cache()  # clear unused memory in PyTorch\n",
        "gc.collect()  # call Python garbage collector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQJerzes3nvz",
        "outputId": "07ca648b-757d-4d63-a6a9-ccf86e0f72a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "583"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnsjYq0jzzxw",
        "outputId": "f289390a-3108-4b8a-b3ec-b3db50d1eaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters 84357792\n"
          ]
        }
      ],
      "source": [
        "N_EMB = 1200\n",
        "N_LAYERS = 4\n",
        "N_HEADS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "\n",
        "def estimate_loss(model, val_data, block_size, batch_size):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, y = get_batch(val_data, block_size, batch_size)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        _, loss = model(x, y)\n",
        "    model.train()\n",
        "    return loss.item()\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.tril(torch.ones(sz, sz)) == 1).float()\n",
        "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def get_sine_position_encodings(length, dim):\n",
        "    pos = torch.arange(length, dtype=torch.float32).reshape(-1, 1)\n",
        "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(math.log(10000.0) / dim))\n",
        "    pos_encodings = torch.zeros(length, dim)\n",
        "    pos_encodings[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pos_encodings[:, 1::2] = torch.cos(pos * div_term)\n",
        "    return pos_encodings\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, n_emb, block_size, n_layers, n_heads, dropout=0.2):\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=n_emb, nhead=n_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(n_emb, 6 * n_emb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6 * n_emb, n_emb)\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        token_emb = self.token_embedding_table(idx)\n",
        "        position_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "\n",
        "        x = token_emb + position_emb\n",
        "        x_transform = x.clone()\n",
        "        mask = generate_square_subsequent_mask(T).to(device)\n",
        "\n",
        "        x_transform = self.transformer_encoder(x_transform.permute(1, 0, 2), mask=mask)\n",
        "        x_transform = x_transform.permute(1, 0, 2)\n",
        "        x = x + x_transform\n",
        "\n",
        "        x = self.feed_forward(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            return logits, None\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, block_size, temperature=1.0, stop_token=False):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self.forward(idx_cond)\n",
        "\n",
        "            # Scale logits by the temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_new = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat([idx, idx_new], dim=-1)\n",
        "            if stop_token and idx_new.item() == end_id:\n",
        "                break\n",
        "        return idx\n",
        "\n",
        "# Create model, optimizer\n",
        "model = LanguageModel(vocab_size=VOCAB_SIZE, block_size=BLOCK_SIZE, n_emb=N_EMB, n_layers=N_LAYERS, \\\n",
        "    n_heads=N_HEADS, dropout=DROPOUT).to(device)\n",
        "\n",
        "print(f'Number of parameters {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5d8MVV6Azzxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01472aba-23ff-46a4-f7d7-11a0537a89c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/datasets/NLP/tiny_stories/english_tiny_stories_4layers.pth\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers.pth\")\n",
        "print(model_path)\n",
        "model = torch.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKRlCdwgzzxy",
        "outputId": "15d4e4a8-6f0e-42b5-f3a7-965608fe6e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 Training Loss: 1.2919141054153442\n",
            "Validation loss: 1.0863735675811768\n",
            "Step: 100 Training Loss: 1.2361135482788086\n",
            "Validation loss: 1.4048341512680054\n",
            "Step: 200 Training Loss: 1.1905324459075928\n",
            "Validation loss: 1.212174892425537\n",
            "Step: 300 Training Loss: 1.194663166999817\n",
            "Validation loss: 1.1724224090576172\n",
            "Step: 400 Training Loss: 1.241074562072754\n",
            "Validation loss: 1.1256732940673828\n",
            "Step: 500 Training Loss: 1.284751057624817\n",
            "Validation loss: 1.148874282836914\n",
            "Step: 600 Training Loss: 1.2424288988113403\n",
            "Validation loss: 1.2228186130523682\n",
            "Step: 700 Training Loss: 1.219326376914978\n",
            "Validation loss: 1.1170852184295654\n",
            "Step: 800 Training Loss: 1.3331797122955322\n",
            "Validation loss: 1.1689926385879517\n",
            "Step: 900 Training Loss: 1.21454918384552\n",
            "Validation loss: 1.2301558256149292\n",
            "Step: 1000 Training Loss: 1.4424545764923096\n",
            "Validation loss: 1.3047943115234375\n",
            "Step: 1100 Training Loss: 1.245028018951416\n",
            "Validation loss: 1.213889479637146\n",
            "Step: 1200 Training Loss: 1.2754627466201782\n",
            "Validation loss: 1.1935557126998901\n",
            "Step: 1300 Training Loss: 1.3432105779647827\n",
            "Validation loss: 1.0803929567337036\n",
            "Step: 1400 Training Loss: 1.2548093795776367\n",
            "Validation loss: 1.2505805492401123\n",
            "Step: 1500 Training Loss: 1.1544499397277832\n",
            "Validation loss: 1.1671196222305298\n",
            "Step: 1600 Training Loss: 1.2611125707626343\n",
            "Validation loss: 1.2770965099334717\n",
            "Step: 1700 Training Loss: 1.1968331336975098\n",
            "Validation loss: 1.1723535060882568\n",
            "Step: 1800 Training Loss: 1.2502175569534302\n",
            "Validation loss: 1.3108758926391602\n",
            "Step: 1900 Training Loss: 1.391462802886963\n",
            "Validation loss: 1.262884497642517\n",
            "Step: 2000 Training Loss: 1.156810998916626\n",
            "Validation loss: 1.2461655139923096\n",
            "Step: 2100 Training Loss: 1.433143138885498\n",
            "Validation loss: 1.291175365447998\n",
            "Step: 2200 Training Loss: 1.4573324918746948\n",
            "Validation loss: 1.3680388927459717\n",
            "Step: 2300 Training Loss: 1.1937731504440308\n",
            "Validation loss: 1.2105605602264404\n",
            "Step: 2400 Training Loss: 1.2704898118972778\n",
            "Validation loss: 1.1132593154907227\n",
            "Step: 2500 Training Loss: 1.3124957084655762\n",
            "Validation loss: 1.1811915636062622\n",
            "Step: 2600 Training Loss: 1.250178337097168\n",
            "Validation loss: 1.0770236253738403\n",
            "Step: 2700 Training Loss: 1.2297848463058472\n",
            "Validation loss: 1.091646671295166\n",
            "Step: 2800 Training Loss: 1.2429437637329102\n",
            "Validation loss: 1.1449699401855469\n",
            "Step: 2900 Training Loss: 1.292833685874939\n",
            "Validation loss: 1.2810181379318237\n"
          ]
        }
      ],
      "source": [
        "EARLY_STOP = 50\n",
        "N_EPOCHS = 3000\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "last_val_loss = 1e9\n",
        "early_stop = EARLY_STOP\n",
        "\n",
        "for steps in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    xb, yb = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Delete xb, yb and free GPU memory\n",
        "    del xb, yb\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if steps % 100 == 0:\n",
        "        print('Step:', steps, 'Training Loss:', loss.item())\n",
        "        val_loss = estimate_loss(model, val_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "        print('Validation loss:', val_loss)\n",
        "        # if val_loss >= last_val_loss:\n",
        "        #     early_stop -= 1\n",
        "        #     if early_stop == 0:\n",
        "        #         print('Early stop!')\n",
        "        #         break\n",
        "        # else:\n",
        "        #     early_stop = EARLY_STOP\n",
        "        #     last_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dh2aOVX1zzxy"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers_2.pth\")\n",
        "torch.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCZ8RJ-zzxz",
        "outputId": "60815dd8-17c6-4dd0-fe1b-9c0dae2a0fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story  1 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She wanted to go back home. She saw a big tree with red apples. She thought, \"This is my chicken. Please, wait!\" But the chicken did not stop. Alice asked her mom, \"Can I eat the apples?\" Her mom said, \"No, Alice. It is not yours. You cannot eat them.\" But Alice did not listen. She climbed the tree and ate the apples. She felt happy.But when she got to the top of the tree, she saw that her chicken was gone. She was sad. Then, a nice squirrel came to help. The squirrel said, \"Don't be sad, Alice. We can share the apples and play together.\" They were both happy.\n",
            "\n",
            "\n",
            "Story  2 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not see her chicken. She was sad. She asked her mom, \"Mom, have you seen my chicken?\"Her mom did not know. She looked around the house and asked, \"Where is the chicken?\"Alice smiled and said, \"I don't know. Maybe it is in the dark, old house.\"Just then, her mom came home. She was holding a big jar of salt. She said, \"Surprise! I put the salt in the jar and turned it out. The chicken turned red and orange.Alice's room was not dark anymore. She was happy.\n",
            "\n",
            "\n",
            "Story  3 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not see it. She was very sad. She missed her chicken, but she could not find it.Then she saw a big dog. The dog was holding the chicken! The dog had her chicken! The dog's name was Bobo. He had a big bag.Alice was so happy to see Bobo. She hugged Bobo and said, \"Let's play together!\" They played all day. The dog was not sad anymore.\n",
            "\n",
            "\n",
            "Story  4 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She saw a big hole in the ground. Alice wanted to get her chicken back. She put her chicken together in the hole.But the flower was too small. It was very dark. Alice was sad. She wanted her chicken back. She asked her mom if she could borrow her chicken. Her mom said yes. Alice was very happy. She took her chicken to the hole. She put it in the hole.But when she was about to take it, the bulb started to move. It tried to roll away. Alice was scared. She had to go home. She felt bad. She cried and cried. She wished she had never opened her chicken in the hole.\n",
            "\n",
            "\n",
            "Story  5 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She felt sad and wanted to find it. She looked around the house, but it was not there. She saw a big pot of water. She thought it would be the chicken. She turned it on and saw the chicken. She did not see it. It was not a chicken! It was a chicken! It had a sharp teeth and a long tongue.Alice was scared. She did not want to get off the chicken. She wanted the chicken. She thought the chicken would be the chicken. She dropped it into the water. She was scared. She did not know how to get out. She wanted to go back home. She cried. She wanted the chicken. She wished she had not found it. She hated the chicken.\n",
            "\n",
            "\n",
            "Story  6 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She wanted to find it. She walked and walked, but she could not find it. Then, she saw a big tree with a hole in it. Alice was excited. She put her chicken in the hole and turned it in.Inside the hole, she found a big, friendly dog. The dog wanted to play and jump in the hole. Alice was scared. She did not want the dog to go away. But she wanted to be nice. She took off her chicken and took off her chicken. She played in the hole until it was time to go home. Alice was happy she found her chicken, and she was not scared anymore.\n",
            "\n",
            "\n",
            "Story  7 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She saw a big rock. She was scared. She did not know where it was. She looked and looked, but she could not find it.Then, she heard a voice. It said, \"Don't be scared, I will help you find your home.\" She looked around and saw her chicken with her chicken. She had a way to get her chicken back. She looked under her bed and in her toy box. She did not see her chicken.Then, a big dog came and took the chicken. The dog took the chicken and flew away. The chicken was happy to be home. She learned that sometimes, we need to help each other and find your home.\n",
            "\n",
            "\n",
            "Story  8 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She saw a big tree with tall green leaves. Alice thought, \"This is my chicken! I want to see it.\" Alice went inside the tree and saw her chicken. She was not scared, but she was not scared. She was happy and said, \"Hello, chicken! My name is Alice. I can help you find your home.\"But the chicken did not hear her. It was too dark. It got lost. Alice did not know where her chicken was. She was very sad and cried. She wished she had never found her chicken.\n",
            "\n",
            "\n",
            "Story  9 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She saw a big leaf and felt a little scared. She held her chicken close to her.The leaf was soft and warm. Alice felt safe in her jar. She smiled and felt happy. She put her chicken away. Alice played with her friends in the park. She felt safe and safe. She played with her friends and her friends. They were happy.\n",
            "\n",
            "\n",
            "Story  10 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She wanted to find it. She looked around the park, but she could not find it. Alice started to cry.Suddenly, she spotted a big bird. The bird had her ticket in its beak. The bird was singing its song. Alice was so happy! She ran away, feeling very proud.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "starting_tokens = 'Alice lost her chicken. She went outside to look for it. But it was dark.'\n",
        "\n",
        "encoded_start = tokenizer.encode(starting_tokens).ids\n",
        "encoded_start.pop(-1)\n",
        "len_starting_tokens = len(encoded_start)\n",
        "\n",
        "idx = torch.tensor(encoded_start).reshape(1, len_starting_tokens).to(device)\n",
        "model.eval()\n",
        "N_SAMPLES = 10\n",
        "for _ in range(N_SAMPLES):\n",
        "    generation = model.generate(idx, max_new_tokens=1000, block_size=BLOCK_SIZE, temperature=0.7, stop_token=True)[0].tolist()\n",
        "    story = tokenizer.decode(generation, skip_special_tokens=True)\n",
        "\n",
        "    print('Story ', _ + 1, ':')\n",
        "    print(story)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}