{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoavu-cs/notebooks/blob/main/tiny_english_stories_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9pHCodg4zzxu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pickle\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "from tokenizers import ByteLevelBPETokenizer, processors\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1qJAVbOe196m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1d0fe6-3962-4ea4-aad5-e035b3a4e257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-qVyof2BgJ",
        "outputId": "300a181d-8636-40d2-d52d-8e20b52ad1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " english_tiny_stories_18m.pth\t      english_tiny_stories_4layers_4.pth\n",
            " english_tiny_stories_28m.pth\t      english_tiny_stories_4layers.pth\n",
            "'english_tiny_stories_2 - Copy.pth'   english_tiny_stories.pth\n",
            " english_tiny_stories_2.pth\t      merges.txt\n",
            " english_tiny_stories_37m.pth\t      TinyStoriesV2-GPT4-train.txt\n",
            " english_tiny_stories_4layers_2.pth   TinyStoriesV2-GPT4-valid.txt\n",
            " english_tiny_stories_4layers_3.pth   vocab.json\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n",
        "data_path = \"/content/drive/My Drive/datasets/NLP/tiny_stories\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'TinyStoriesV2-GPT4-train.txt'\n",
        "val_filename = 'TinyStoriesV2-GPT4-valid.txt'\n",
        "\n",
        "filepath = os.path.join(data_path, filename)\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    train_data = file.read()\n",
        "train_data = train_data.replace('\\n', '')\n",
        "train_data = train_data.split('<|endoftext|>')\n",
        "\n",
        "val_filepath = os.path.join(data_path, val_filename)\n",
        "with open(val_filepath, 'r', encoding='utf-8') as file:\n",
        "    val_data = file.read()\n",
        "val_data = val_data.replace('\\n', '')\n",
        "val_data = val_data.split('<|endoftext|>')\n",
        "\n",
        "print(train_data[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cJ6Gsjjjqi4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198dd90f-c28b-4e6a-eceb-7b70f0281890"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.DataFrame(train_data, columns=['content'])\n",
        "val_data = pd.DataFrame(val_data, columns=['content'])\n",
        "\n",
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "\n",
        "print(train_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB6DsNYWK6Gr",
        "outputId": "900a101e-2468-42ad-a79d-fe223e51a2a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2717700, 1)\n",
            "(27631, 1)\n",
            "                                             content\n",
            "0  Once upon a time there was a little boy named ...\n",
            "1  Once upon a time, there was a reliable otter n...\n",
            "2  One day, a little boy named Tim went to the pa...\n",
            "3  Once upon a time there was a friendly little b...\n",
            "4  Once upon a time, in a small house, there live...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "tokenizer.train(files=[os.path.join(data_path, 'TinyStoriesV2-GPT4-valid.txt')], vocab_size=10000, min_frequency=1, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "tokenizer.save_model(data_path)"
      ],
      "metadata": {
        "id": "1VFv6VYZrenp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d263f13-a962-4e9d-96f9-71236aaab3c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/datasets/NLP/tiny_stories/vocab.json',\n",
              " '/content/drive/My Drive/datasets/NLP/tiny_stories/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_path = os.path.join(data_path, \"vocab.json\")\n",
        "merge_path = os.path.join(data_path, \"merges.txt\")\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    vocab=vocab_path,\n",
        "    merges=merge_path\n",
        ")\n",
        "\n",
        "tokenizer.add_special_tokens([\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "\n",
        "tokenizer._tokenizer.post_processor = processors.BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "VOXL-GXxr2Oq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Encode a text string\n",
        "print(train_data.loc[0, 'content'])\n",
        "output = tokenizer.encode(train_data.loc[0, 'content']).ids\n",
        "print(\"Decoded string: \", tokenizer.decode(output, skip_special_tokens=False))  # decoding back to the original string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLmGXW9Usx3v",
        "outputId": "eeb60dbe-ad9c-4822-9d28-cd418c1f0f22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!\n",
            "Decoded string:  <s>Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  He said, “Wow, that is a really amazing vase! Can I buy it?” The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. And that's how Ben found an amazing vase in the store!</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yQ9D6gFazzxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244e7f74-807b-4e3f-ab2b-016109b9f480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is  10000\n"
          ]
        }
      ],
      "source": [
        "BLOCK_SIZE = 256\n",
        "VOCAB_SIZE = len(tokenizer.get_vocab())\n",
        "print('Vocab size is ', VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eot_id = tokenizer.token_to_id(\"<|endoftext|>\")\n",
        "start_id = tokenizer.token_to_id(\"<s>\")\n",
        "end_id = tokenizer.token_to_id(\"</s>\")\n",
        "pad_id = tokenizer.token_to_id(\"<pad>\")\n",
        "unk_id = tokenizer.token_to_id(\"<unk>\")"
      ],
      "metadata": {
        "id": "A17FtD1XtLx0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMAvqIY8zzxw",
        "outputId": "bab4cff1-68e9-4977-f2cc-73d881222487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256]) torch.Size([1, 256])\n",
            "<s>Once upon a time, there was a cat named Lucy. Lucy was very flexible. She could bend and twist in many ways. One day, Lucy met a dog named Tom. Tom was very nice, and they became good friends.One day, Lucy told Tom, \"I am going to prepare for a big party. It is a marriage party for my friend, the bird.\" Tom was excited and said, \"I want to help too!\" So, they both started to get things ready for the marriage party.As they were preparing, they found a big, red ball. Lucy said, \"Let's play with the ball, but we must be careful not to break anything for the party.\" They played with the ball, but it bounced too high and knocked over a vase. They were sad, but they remembered they were flexible. They worked together to fix the vase and make it look nice again.The marriage party was a big success. All the animals had a great time. Lucy and Tom were happy that they could help and that their flexibility saved the day. They knew they would be friends forever.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Once upon a time, there was a cat named Lucy. Lucy was very flexible. She could bend and twist in many ways. One day, Lucy met a dog named Tom. Tom was very nice, and they became good friends.One day, Lucy told Tom, \"I am going to prepare for a big party. It is a marriage party for my friend, the bird.\" Tom was excited and said, \"I want to help too!\" So, they both started to get things ready for the marriage party.As they were preparing, they found a big, red ball. Lucy said, \"Let's play with the ball, but we must be careful not to break anything for the party.\" They played with the ball, but it bounced too high and knocked over a vase. They were sad, but they remembered they were flexible. They worked together to fix the vase and make it look nice again.The marriage party was a big success. All the animals had a great time. Lucy and Tom were happy that they could help and that their flexibility saved the day. They knew they would be friends forever.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "def get_batch(data, block_size, batch_size):\n",
        "    x = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    y = torch.zeros((batch_size, block_size), dtype=torch.long)\n",
        "    samples = data['content'].sample(n=batch_size)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        summary_ids = tokenizer.encode(sample).ids\n",
        "        #summary_ids = [id for id in summary_ids if id != UNK_ID]\n",
        "        if len(summary_ids) < block_size + 2:\n",
        "            summary_ids = summary_ids + [pad_id] * (block_size + 2 - len(summary_ids))\n",
        "        random_start = random.randint(0, len(summary_ids) - block_size - 2)\n",
        "        x[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start:random_start + block_size], dtype=torch.long)\n",
        "        y[i, :len(summary_ids)] = torch.tensor(summary_ids[random_start + 1:random_start + block_size + 1], dtype=torch.long)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "a, b = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=1)\n",
        "print(a.shape, b.shape)\n",
        "print(tokenizer.decode(a[0].tolist(), skip_special_tokens=False))\n",
        "print(tokenizer.decode(b[0].tolist(), skip_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model  # delete the tensor variable\n",
        "torch.cuda.empty_cache()  # clear unused memory in PyTorch\n",
        "gc.collect()  # call Python garbage collector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQJerzes3nvz",
        "outputId": "07ca648b-757d-4d63-a6a9-ccf86e0f72a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "583"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnsjYq0jzzxw",
        "outputId": "97cc6913-a2e9-4af9-eaab-c5de118c862d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters 84357792\n"
          ]
        }
      ],
      "source": [
        "N_EMB = 1200\n",
        "N_LAYERS = 4\n",
        "N_HEADS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "\n",
        "def estimate_loss(model, val_data, block_size, batch_size):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x, y = get_batch(val_data, block_size, batch_size)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        _, loss = model(x, y)\n",
        "    model.train()\n",
        "    return loss.item()\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.tril(torch.ones(sz, sz)) == 1).float()\n",
        "    mask = mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def get_sine_position_encodings(length, dim):\n",
        "    pos = torch.arange(length, dtype=torch.float32).reshape(-1, 1)\n",
        "    div_term = torch.exp(torch.arange(0, dim, 2).float() * -(math.log(10000.0) / dim))\n",
        "    pos_encodings = torch.zeros(length, dim)\n",
        "    pos_encodings[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pos_encodings[:, 1::2] = torch.cos(pos * div_term)\n",
        "    return pos_encodings\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, n_emb, block_size, n_layers, n_heads, dropout=0.2):\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=n_emb, nhead=n_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(n_emb, 6 * n_emb),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6 * n_emb, n_emb)\n",
        "        )\n",
        "\n",
        "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        token_emb = self.token_embedding_table(idx)\n",
        "        position_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "\n",
        "        x = token_emb + position_emb\n",
        "        x_transform = x.clone()\n",
        "        mask = generate_square_subsequent_mask(T).to(device)\n",
        "\n",
        "        x_transform = self.transformer_encoder(x_transform.permute(1, 0, 2), mask=mask)\n",
        "        x_transform = x_transform.permute(1, 0, 2)\n",
        "        x = x + x_transform\n",
        "\n",
        "        x = self.feed_forward(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            return logits, None\n",
        "\n",
        "\n",
        "    def generate(self, idx, max_new_tokens, block_size, temperature=1.0, stop_token=False):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, _ = self.forward(idx_cond)\n",
        "\n",
        "            # Scale logits by the temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_new = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat([idx, idx_new], dim=-1)\n",
        "            if stop_token and idx_new.item() == end_id:\n",
        "                break\n",
        "        return idx\n",
        "\n",
        "# Create model, optimizer\n",
        "model = LanguageModel(vocab_size=VOCAB_SIZE, block_size=BLOCK_SIZE, n_emb=N_EMB, n_layers=N_LAYERS, \\\n",
        "    n_heads=N_HEADS, dropout=DROPOUT).to(device)\n",
        "\n",
        "print(f'Number of parameters {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5d8MVV6Azzxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff77365-206c-4b77-9c1f-8b5fdcf53f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/datasets/NLP/tiny_stories/english_tiny_stories_4layers_4.pth\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers_4.pth\")\n",
        "print(model_path)\n",
        "model = torch.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKRlCdwgzzxy",
        "outputId": "f54fb3c3-b9f4-4609-ca79-2e0676600286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 Training Loss: 1.2261215448379517\n",
            "Validation loss: 1.128421664237976\n",
            "Step: 100 Training Loss: 1.221932291984558\n",
            "Validation loss: 1.1410911083221436\n",
            "Step: 200 Training Loss: 1.3988884687423706\n",
            "Validation loss: 1.1491354703903198\n",
            "Step: 300 Training Loss: 1.1345525979995728\n",
            "Validation loss: 1.1668723821640015\n",
            "Step: 400 Training Loss: 1.3599227666854858\n",
            "Validation loss: 1.1187361478805542\n",
            "Step: 500 Training Loss: 1.325697422027588\n",
            "Validation loss: 1.2319445610046387\n",
            "Step: 600 Training Loss: 1.221115231513977\n",
            "Validation loss: 1.1161452531814575\n",
            "Step: 700 Training Loss: 1.27701735496521\n",
            "Validation loss: 1.0766260623931885\n",
            "Step: 800 Training Loss: 1.3061267137527466\n",
            "Validation loss: 0.9964842200279236\n",
            "Step: 900 Training Loss: 1.311370611190796\n",
            "Validation loss: 1.2460650205612183\n",
            "Step: 1000 Training Loss: 1.3252227306365967\n",
            "Validation loss: 1.1362639665603638\n",
            "Step: 1100 Training Loss: 1.1369783878326416\n",
            "Validation loss: 1.2230286598205566\n",
            "Step: 1200 Training Loss: 1.1580464839935303\n",
            "Validation loss: 1.033205509185791\n",
            "Step: 1300 Training Loss: 1.405816912651062\n",
            "Validation loss: 1.1849241256713867\n",
            "Step: 1400 Training Loss: 1.1523739099502563\n",
            "Validation loss: 1.195902943611145\n",
            "Step: 1500 Training Loss: 1.1996033191680908\n",
            "Validation loss: 1.1497673988342285\n",
            "Step: 1600 Training Loss: 1.2327172756195068\n",
            "Validation loss: 1.1428736448287964\n",
            "Step: 1700 Training Loss: 1.4300131797790527\n",
            "Validation loss: 1.0743629932403564\n",
            "Step: 1800 Training Loss: 1.2606356143951416\n",
            "Validation loss: 0.9697145223617554\n",
            "Step: 1900 Training Loss: 1.192719578742981\n",
            "Validation loss: 1.1115823984146118\n",
            "Step: 2000 Training Loss: 1.127787709236145\n",
            "Validation loss: 1.1214677095413208\n",
            "Step: 2100 Training Loss: 1.362612247467041\n",
            "Validation loss: 1.1587361097335815\n",
            "Step: 2200 Training Loss: 1.0637493133544922\n",
            "Validation loss: 1.1699700355529785\n",
            "Step: 2300 Training Loss: 1.198954701423645\n",
            "Validation loss: 1.0691466331481934\n",
            "Step: 2400 Training Loss: 1.242357850074768\n",
            "Validation loss: 1.00653874874115\n",
            "Step: 2500 Training Loss: 1.3260647058486938\n",
            "Validation loss: 1.0941250324249268\n",
            "Step: 2600 Training Loss: 1.1268374919891357\n",
            "Validation loss: 1.020362377166748\n",
            "Step: 2700 Training Loss: 1.1090545654296875\n",
            "Validation loss: 1.038128137588501\n",
            "Step: 2800 Training Loss: 1.21434485912323\n",
            "Validation loss: 0.9719647169113159\n",
            "Step: 2900 Training Loss: 1.1584136486053467\n",
            "Validation loss: 1.3231420516967773\n",
            "Step: 3000 Training Loss: 1.0589406490325928\n",
            "Validation loss: 1.1954880952835083\n",
            "Step: 3100 Training Loss: 1.2142419815063477\n",
            "Validation loss: 1.0947855710983276\n",
            "Step: 3200 Training Loss: 1.1542645692825317\n",
            "Validation loss: 1.1842873096466064\n",
            "Step: 3300 Training Loss: 1.1582986116409302\n",
            "Validation loss: 1.0845811367034912\n",
            "Step: 3400 Training Loss: 1.0121017694473267\n",
            "Validation loss: 1.1959021091461182\n",
            "Step: 3500 Training Loss: 1.2246767282485962\n",
            "Validation loss: 0.9869951605796814\n",
            "Step: 3600 Training Loss: 1.2145940065383911\n",
            "Validation loss: 1.223557710647583\n",
            "Step: 3700 Training Loss: 1.2669423818588257\n",
            "Validation loss: 1.0809532403945923\n",
            "Step: 3800 Training Loss: 1.246809959411621\n",
            "Validation loss: 1.090184211730957\n",
            "Step: 3900 Training Loss: 1.2957909107208252\n",
            "Validation loss: 1.0739891529083252\n",
            "Step: 4000 Training Loss: 1.0365601778030396\n",
            "Validation loss: 0.9885940551757812\n",
            "Step: 4100 Training Loss: 1.2174575328826904\n",
            "Validation loss: 1.1173038482666016\n",
            "Step: 4200 Training Loss: 1.2423362731933594\n",
            "Validation loss: 1.0429326295852661\n",
            "Step: 4300 Training Loss: 1.2782014608383179\n",
            "Validation loss: 1.0851614475250244\n",
            "Step: 4400 Training Loss: 1.271499752998352\n",
            "Validation loss: 1.1300725936889648\n",
            "Step: 4500 Training Loss: 1.1371269226074219\n",
            "Validation loss: 1.0938913822174072\n",
            "Step: 4600 Training Loss: 1.1353615522384644\n",
            "Validation loss: 1.1277236938476562\n",
            "Step: 4700 Training Loss: 1.201910376548767\n",
            "Validation loss: 1.057233214378357\n",
            "Step: 4800 Training Loss: 1.1583685874938965\n",
            "Validation loss: 1.1611182689666748\n",
            "Step: 4900 Training Loss: 1.094627022743225\n",
            "Validation loss: 1.0149781703948975\n"
          ]
        }
      ],
      "source": [
        "EARLY_STOP = 50\n",
        "N_EPOCHS = 5000\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "last_val_loss = 1e9\n",
        "early_stop = EARLY_STOP\n",
        "\n",
        "for steps in range(N_EPOCHS):\n",
        "    model.train()\n",
        "    xb, yb = get_batch(train_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "    xb = xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Delete xb, yb and free GPU memory\n",
        "    del xb, yb\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if steps % 100 == 0:\n",
        "        print('Step:', steps, 'Training Loss:', loss.item())\n",
        "        val_loss = estimate_loss(model, val_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
        "        print('Validation loss:', val_loss)\n",
        "        # if val_loss >= last_val_loss:\n",
        "        #     early_stop -= 1\n",
        "        #     if early_stop == 0:\n",
        "        #         print('Early stop!')\n",
        "        #         break\n",
        "        # else:\n",
        "        #     early_stop = EARLY_STOP\n",
        "        #     last_val_loss = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dh2aOVX1zzxy"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(data_path, \"english_tiny_stories_4layers_4.pth\")\n",
        "torch.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCZ8RJ-zzxz",
        "outputId": "1a6df4fe-c0cb-40f7-87a3-e6acebcd9bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story  1 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. Suddenly, she saw a big yellow butterfly fluttering by. She wanted to catch it.Alice chased the butterfly, but it flew away.Alice was sad. She wanted her chicken back. She asked her mom to help her get her chicken back. Her mom said yes and gave her a hug.Alice smiled and ran back to get the chicken out. She had seen it before. The chicken was still out of sight.Alice was so happy and excited. She forgot about her chicken. She ran back inside. She told her friends about the nice yellow butterfly and they all helped her get the chicken out.Alice's friends were very proud of her. They all thanked Alice for helping them get the chicken back.\n",
            "\n",
            "\n",
            "Story  2 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She was sad because it couldn't find it.Alice asked her mom if she could have it. Her mom said no.Alice was very sad and ran away. She never found the chicken or her chicken.Alice never found her chicken. From then on, she was never sad again.\n",
            "\n",
            "\n",
            "Story  3 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to feel weak because she couldn't find it.Alice called out to her mama and asked, \"Mama, where is my chicken?\" Mama replied, \"I think I know, sweetheart. I think I saw it near the big tree. We need it.\"Alice and Mama walked to the big tree and saw a big tree with red apples. Alice reached up and picked an apple. She said, \"Yum! I'm so happy you found my chicken. But it's far away and I didn't know someone it belongs to.\"Mama smiled and said, \"That's right. I'm glad you found it. We can get it later that you found it.\"Alice nodded and said, \"Ok Mama!\" Mama picked up the apple and gave it to Alice. It was a sweet and juicy apple. She said, \"Thank you Mama! I love you and so much!\" Mama and her mama nodded and said, \"We're glad you're happy. Come back anytime.\"\n",
            "\n",
            "\n",
            "Story  4 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She was very sad.Then she noticed something in the corner of her backyard. It was a big, juicy worm! She crawled around the garden and tried to pick it up.Suddenly she heard a noise. It was her chicken!Alice shouted to her chicken, \"I found the worm! It's so soft and bouncy!\"Her chicken laughed and said, \"Yes, it's very yummy!\"Alice looked over the jar and saw that it had a special thorn inside. She tried to pick it up, but it was too heavy for her.Alice felt upset by she couldn't pick up the worm. She wanted to know what was wrong with her, but she didn't know what to do. She looked out from the window and saw her chicken sitting on the grass. She waved her paw and said, \"Don't worry, my chicken will pull you out of my home.\"Alice picked up the worm and pulled it out of the hole. She was so happy! She hugged the worm and said, \"Thank you, May my onion!\"The chicken was so happy that it gave Alice a big hug. Ellie and her chicken were so happy and were not upset anymore.\n",
            "\n",
            "\n",
            "Story  5 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She was scared, but she was curious.As she wandered around, something caught her eye. She stopped and looked up to see a bird. It had landed on the ostrich's hand.Alice was very frightened. What could have it answer?\", she said again. The ostrich said, \"I'm sorry, Alice. I was so scared of the dark\".Alice thought for a moment. \"It's ok, I know what happened.\"Alice smiled and said, \"Let's try if we want.\"Alice nodded and they found a long stick. They took the stick and tried to poke the ostrich's nose. At first, but the ostrich still wasn't scared.Alice tried to pick up the stick, but the ostrich didn't move.Alice tried to help, but she couldn't. The ostrich was too fast and too hot.Alice was sad. She said, \"You're not safe, sweetheart. That's not nice of the boy. You can't throw things as you like.\"Alice understood that she was wrong.\n",
            "\n",
            "\n",
            "Story  6 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She was so sad. She ran back home as fast as she could.When she got there, she saw something strange. There was a big sign coming out of the house. The sign said \"Win.\"Alice wondered what was in the line. Then her mom had an idea. She went to the store and bought a ticket. Then she took out her ticket and it was gone.Alice was so excited. She opened the pale sign and found the chicken inside!Alice said, \"Mom, I found your chicken!\" Her mom smiled and said, \"That's a very nice ticket! You found it!\"Alice was so happy. She could barely contain her excitement. She ran off to show her mom her ticket and they both laughed.\n",
            "\n",
            "\n",
            "Story  7 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She was feeling scared and scared. Suddenly, she spotted a big bird. The bird had a big beak and shiny feathers on its feathers.Alice wanted to say hello, but she didn't know what to say. Then she had an idea. She asked the bird, “Can I have a hug?” The bird said, “Of course you can. I think you can give me a hug.\"Alice was so excited. She hugged it and felt safe and happy, - they made a new friend out of sticks.\n",
            "\n",
            "\n",
            "Story  8 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She walked and walked until she found it. She was so scared.Alice started to cry. She went back home and told her mom what had happened. Her mom hugged her and said, \"Don't worry, sweetheart. I'm here to help you find your chicken.\"Alice smiled and followed her mom inside. When they arrived, she saw the chicken was holding still on the grass. She smiled and said, \"Thank you, mum. You are very kind.\"Her mom smiled back and said, \"You're welcome, Alice. I'm happy you found your chicken. You're safe now.\"Alice waved goodbye and went inside, feeling brave and warm.\n",
            "\n",
            "\n",
            "Story  9 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to feel a shiver coming her way. Finally, she saw a pond.“Where is my chicken?” she asked.Suddenly, she saw a big brown horse. “I found your chicken,” she said.When she touched the cows, she saw any chickens in it. It was too hot!Alice was very scared. She ran back inside her house. But her mom told her it was time to go inside. She said goodbye to the farm and went inside in her house, dry and warm.\n",
            "\n",
            "\n",
            "Story  10 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not see her chicken anywhere. She started to feel too hot.Suddenly, her chicken came in the dark and roared and ran away.Alice was so scared, she started to cry. She was so scared that she started to cry.But then, a friendly dog saw her crying and asked, \"Why are you crying?\"Alice told the dog about her lost chicken. The dog said, \"Don't worry. I'll help you find it.\" The dog led the dog to a tall tree.Alice was so happy, she hugged the dog. She thanked the dog and said goodbye. In the end, she knew she could always find her chicken.\n",
            "\n",
            "\n",
            "Story  11 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to struggle and tremble. She thought she could never find it.Alice saw a big cat and said, \"Meow, meow, meow!\" But the cat didn't answer. She kept walking and looking around. Suddenly, she saw a little boy. He said, \"I found your chicken. It was hiding somewhere in the grass.\"Alice shouted, \"No! That is not your chicken! That's my chicken. She is hiding somewhere else.\" The boy laughed and chased after her.Alice was relieved. She ran to the neighbour's house. She hugged the cow and said, \"Thank you for helping me. I was looking for my chicken. I wanted to find it.\" The boy said, \"You're welcome, Alice. I'm glad you found your chicken. Here, you can have my chicken.\"Alice thanked the boy and went back to her house. She learned a lesson about her chicken and the boy.\n",
            "\n",
            "\n",
            "Story  12 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not see anything.Alice asked her Mom, \"Mom, where is my chicken?\" Her Mom said, \"Don't worry, we'll look together.\"Alice kept looking, until she found her chicken. It was holding the chicken!Alice was so happy, she hugged the chicken and said, \"Thank you, Mom!\" Then she spotted a trail of ants in the distance. She got curious and watched the ants for a while. She thought it would be fun to follow them.Alice took the ants outside and walked outside. She looked around and saw different kinds of busy ants. They were busy eating food.Alice asked her Mom, \"Can I follow the ants, Mum?\" Her Mom said, \"Sure!\"Alice followed the ants on the trail and went back to her home.Alice was so excited about her collection. She could not wait to tell her friends about it.\n",
            "\n",
            "\n",
            "Story  13 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. Suddenly, she saw the chickens, its chickens, and the chickens. She said “Where are you going?”Her chickens told her it was going to be hiding.As Alice looked around, she saw a little bird sitting on a bush. Its feathers were not moving.Alice wanted to help the bird, so she picked up a stick and tried to throw the stick at it. But she missed and fell down. The stick hit Alice's hand and she cried.The chickens felt embarrassed and stopped playing. They said “It’s okay, I can help you.”Alice smiled and picked up the stick. Then she carried it home to her mom. Her mom was very happy that Alice was safe. She gave Alice a big hug and a cookie. It was the same kind of the deer.Alice learned that it was important to help others and to be safe. And someone else can be there to help you.\n",
            "\n",
            "\n",
            "Story  14 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She felt cold and helpless. Suddenly she noticed a small bird perched on a twig. The bird was singing a happy song.Alice tried to catch the bird, but it flew away. She was worried she would miss the bird because she could not catch it.Alice tried to catch the bird, but she was too small. She was upset but she didn't give up.Alice kept trying to catch the bird. In return, she finally caught the bird. She was so happy.Alice learned that it's better to ask for help when you need it. She learned that it's okay to ask for help when you need it. It's good to ask for help before you need it.\n",
            "\n",
            "\n",
            "Story  15 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not find it. She started to cry.“Mom, there's a blueberry,” said Alice, who was very worried and offered to help.“Don’t cry, my darling. I will find you,” her mom said.So they went and looked under the trees. Then, they saw a squirrel. It had a long tail and wanted to take it away.\"Do you want to take my apple?” asked Alice.“Yes, please!” answered her mom.The squirrel was happy and thankful. “Yes, please!\"SoAlice took the apple and threw it away. The squirrel skipped away and looked for it. On the way back, they saw a big tree with a big nest on it.“Look, it’s! This looks so pretty,” said her mom.“ seeing it,” said Alice. “Yes, it is. You are very lucky. I will let you keep it,” said her mom with a smile.\n",
            "\n",
            "\n",
            "Story  16 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could hear her chicken climb on its soil.Alice went over to get it. The chicken said, “That’s my chicken! You must let it go.”Alice was surprised. She said, “No, I don’t want your chicken!”The chicken said, “But you can’t take it.”Alice was sad. She didn’t want to do something for her chicken. She thought to herself, “Let’t take your chicken, Mommy. She can make it come alive again. So she said, “No, it’s her chicken. You don’t have it.”Alice was so disappointed. She didn’t know what to do. Then she had an idea. She turned it as a toy. She said, “I’ll do it. I can make your chicken go back.”Alice's chicken was happy. She said, “That’s a good decision. Now let’s go back to the garden and play with the chicken again later.”\n",
            "\n",
            "\n",
            "Story  17 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. The sun was out and it was very cold.Alice was sad. She wanted her chicken back. She looked around and saw that she was looking up. She asked her cow, \"Can I have my chicken back, please?\"\"Sure, you can have the chicken. It is very soft and warm,\" said Alice.Alice was grateful. She took the chicken home and played with it. She made her chicken happy. She said, \"You are a good helper, Alice.\"Alice was happy too. She said, \"You are the best chicken ever, Alice. I will always remember you\".Alice said, \"You are a good helper. I will always remember you.\"Alice and Alice played together every day. They always kept the chicken close and fit on the warm bed.\n",
            "\n",
            "\n",
            "Story  18 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to feel scared.Her father came out from behind the trees. He was holding something in his hand.He said, \"Alice, why are you here so dark?\"Alice replied, \"I am scared of dark leaves. I was just looking for my chicken. I am scared.\"Her father smiled and said, \"That's okay, you don't know any better. But you can still think about something fun and have fun. You don't need to be scared of things of things.\"Alice smiled and said, \"I understand, Dad. I won't be scared anymore. I will always remember you and make you feel better. Now, why don't you go and play with your chicken?\"Her father laughed and said, \"Sure, you can. But remember, please be careful with what you have.\"Alice followed his father to the end of the day. She was happy that she had her chicken home safe and sound.\n",
            "\n",
            "\n",
            "Story  19 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She started to feel scared.Suddenly, she heard a noise coming from the barn. She was very scared and wanted to cry.It started to rain heavily, and Sophie started to cry. Her mom came inside and saw the warm milk and ran inside. She hugged her and said, \"Don't cry. I'll get you some milk.\" Then she took off. She began to drink the milk. It was so delicious! Grandma smiled and said, \"It's ok, Sophie. It's just a little duck. See, be careful, ok?\".  Jenny felt better and smiled and said, \"OK, Mommy. I will listen next time I give you milk.\"\n",
            "\n",
            "\n",
            "Story  20 :\n",
            "Alice lost her chicken. She went outside to look for it. But it was dark. She could not see it anymore.Suddenly, she heard a loud noise coming from the bushes. It was her chicken! She had never seen her chicken so close before.Alice screamed for help, but nobody could hear her. She was very sad.Alice shouted for help. She tried to run away, but no one heard her.Alice was worried, but she didn't give up. She tried to find her chicken, but she couldn't.When Alice found her chicken, she was so scared that she started to cry.Alice's chicken flew in and said, \"I'm sorry, Alice. I was not gone. I just wanted to help you.\"Alice was so sad and she never came back.Alice went back to her house and never found her chicken again.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "starting_tokens = 'Alice lost her chicken. She went outside to look for it. But it was dark.'\n",
        "\n",
        "encoded_start = tokenizer.encode(starting_tokens).ids\n",
        "encoded_start.pop(-1)\n",
        "len_starting_tokens = len(encoded_start)\n",
        "\n",
        "idx = torch.tensor(encoded_start).reshape(1, len_starting_tokens).to(device)\n",
        "model.eval()\n",
        "N_SAMPLES = 20\n",
        "for _ in range(N_SAMPLES):\n",
        "    generation = model.generate(idx, max_new_tokens=1000, block_size=BLOCK_SIZE, temperature=0.8, stop_token=True)[0].tolist()\n",
        "    story = tokenizer.decode(generation, skip_special_tokens=True)\n",
        "\n",
        "    print('Story ', _ + 1, ':')\n",
        "    print(story)\n",
        "    print('\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}