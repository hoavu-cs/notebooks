{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)\n",
    "\n",
    "\n",
    "def get_batch(data, block_size, batch_size):\n",
    "    idx = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([train_data[i:i+block_size] for i in idx])\n",
    "    y = torch.stack([train_data[i+1:i+block_size+1] for i in idx])\n",
    "    return x, y\n",
    "\n",
    "def estimate_loss(model, val_data, block_size, batch_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = get_batch(val_data, block_size, batch_size)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        _, loss = model(x, y)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "# xb, yb = get_batch('train', block_size=10, batch_size=4)\n",
    "# print('inputs:', xb.shape, xb.dtype, xb)\n",
    "# print('targets:', yb.shape, yb.dtype, yb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) / (C**0.5)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = F.dropout(wei, p=dropout)\n",
    "        # perform score aggregation\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_emb, n_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        x = self.proj(x)\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        return x\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_emb, 4*n_emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_emb, n_emb),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer Block followed by computation\n",
    "    \"\"\"\n",
    "    def __init__(self, n_emb, n_heads):\n",
    "        super().__init__()\n",
    "        self.head_size = n_emb // n_heads\n",
    "        self.sa = MultiHeadAttention(n_heads, self.head_size)\n",
    "        self.ff = FeedForward()\n",
    "        self.ln1 = nn.LayerNorm(n_emb)\n",
    "        self.ln2 = nn.LayerNorm(n_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        return x\n",
    "        \n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, n_emb):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_emb)\n",
    "        self.blocks = nn.Sequential(*[Block(n_emb, n_heads) for _ in range(n_layers)])\n",
    "        self.feed_forward = FeedForward()\n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(idx)\n",
    "        position_emb = self.position_embedding_table(torch.arange(T, device=device)) \n",
    "        x = token_emb + position_emb\n",
    "        x = self.blocks(x) \n",
    "        x = self.feed_forward(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self.forward(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_new = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_new], dim=-1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deng.txt\n",
      "1164532\n",
      "\n",
      "Mao Mao\n",
      "Cha tôi Đặng Tiểu Bình những năm tháng Cách mạng văn hóa\n",
      "1. Năm 1966 lắm chuyện\n",
      "Ngày 16.5.1966, hội nghị Bộ Chính trị Đảng cộng sản Trung quốc mở rộng thông qua “Thông cáo của Ban thường vụ Trung ương Đảng cộng sản Trung quốc”, tức là Thông cáo 16-5. Việc này đánh dấu cho sự bùng nổ cuộc Đại cách mạng văn hoá của giai cấp vô sản chưa từng có trong lịch sử.Cách mạng văn hoá bùng nổ, chẳng phải chuyện ngẫu nhiên, mà nó là sản phẩm tất yếu của sai lầm tả khuynh, phát triển tới chỗ cực đoan trong nội bộ đảng.Sau ngày lập quốc, qua hơn bảy năm thực tiễn xây dựng, cải tạo thành công của xã hội chủ nghĩa, với sự ánh hưởng của rất nhiều nhân tố trong nước, ngoài nước, trong nội bộ đảng ta đã bắt dầu lan tràn triền miên một loại siêu thắng lợi và tự mãn, cùng với cái đầu nóng hổi chứa đầy những hớn hở và kiêu ngạo. Đã đánh giá hiện thực và thành tựu quá cao, nóng lòng bước vào chủ nghĩa cộng sản, đã làm nảy sinh, phát triển những biện pháp không thiết thực, nên đã có những hành động mạ\n",
      "Vocab size: 161\n",
      "Sample dict: {'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '%': 4, '&': 5, '(': 6, ')': 7, ',': 8, '-': 9}\n",
      "Sample dict: {0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '%', 5: '&', 6: '(', 7: ')', 8: ',', 9: '-'}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#filename = 'datasets/text/1001nights.txt'\n",
    "\n",
    "folder_path = 'datasets/text/'\n",
    "number_of_files = 1\n",
    "data = []\n",
    "\n",
    "counter = 0\n",
    "file_names = os.listdir(folder_path)[:number_of_files]\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    with open(folder_path + file_name, 'r', encoding='utf-8') as file:\n",
    "        data.append(file.read())\n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print(counter, 'files processed')\n",
    "\n",
    "text = '\\n'.join(data)\n",
    "print(len(text))\n",
    "print(text[:1000])\n",
    "\n",
    "stoi = {ch: i for i, ch in enumerate(sorted(set(text)))}\n",
    "itos = {i: ch for i, ch in enumerate(sorted(set(text)))}\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "print('Vocab size:', len(stoi))\n",
    "print('Sample dict:', {k: stoi[k] for k in list(stoi)[:10]})\n",
    "print('Sample dict:', {k: itos[k] for k in list(itos)[:10]})\n",
    "\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device)\n",
    "\n",
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "block_size = 300\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 300]) torch.Size([32, 300])\n",
      "Step: 0 Training Loss: 5.265714168548584\n",
      "Validation loss: 4.578218460083008\n",
      "torch.Size([32, 300]) torch.Size([32, 300])\n",
      "torch.Size([32, 300]) torch.Size([32, 300])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m logits, loss \u001b[39m=\u001b[39m m(xb, yb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hvu2/Git/notebooks/transformer_language_modeling_cleaned.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_emb = 300\n",
    "n_epochs = 10000\n",
    "n_layers = 5\n",
    "n_heads = 5\n",
    "dropout = 0.3\n",
    "learning_rate = 3e-4\n",
    "\n",
    "early_stop = 10\n",
    "last_val_loss = 1e9\n",
    "\n",
    "m = LanguageModel(vocab_size=vocab_size, n_emb=n_emb).to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for steps in range(n_epochs):\n",
    "    xb, yb = get_batch(train_data, block_size, batch_size)\n",
    "    print(xb.shape, yb.shape)\n",
    "    xb = xb.to(device)\n",
    "    \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 100 == 0:\n",
    "        print('Step:', steps, 'Training Loss:', loss.item())\n",
    "        val_loss = estimate_loss(m, val_data, block_size, batch_size)\n",
    "        print('Validation loss:', val_loss)\n",
    "        if val_loss >= last_val_loss:\n",
    "            early_stop -= 1\n",
    "            if early_stop == 0:\n",
    "                print('Early stop!')\n",
    "                break\n",
    "        else:\n",
    "            early_stop = 5\n",
    "            last_val_loss = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17006265\n",
      "Ngày xửa ngày xưa quản hit tội thê-qỦaza,- Hoộc xo Thế vật trời khôi, Tuồng rau đám 10gn Hy.-Bật Tọc Trự Đọng ngòn nh\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor(encode('Ngày xửa ngày xưa')).reshape(1, 17).to(device)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ngày xửa ngày xưa, bằng ngrên bậc ngựời thúc vàng như lời áo quả những giả để sau trong họ mê tráng. Cháu vào mệnh được từ goặc gần ăn xố người tụi hoàng miên trêng chừng. Vua một rượu quẳng thì hng bệnh để ngì ngồi với đến theo lâu gù phục hài vừa bắt, trên số sung! Đó dẫn cùng cho quốc về vọi công cho Aliu kỳ đuốc phải thứ những cách hào anh làm thường về thay, khản bờ vị cần già nhữ chúa bà, cha lúc vợ chúng. Anh ta chồm cung lại kiển. Khi lực đó nơi. Chưa: mỗi ấy ý quá với ông có tôiết bọn bà ngủ mình thì đến nào một ngồ của mình cho chúng tôi, điện phận đánh đâu để phong muốn bị nếu đó các của có tên đất thần hiệm với con. Công chấp đấm triết cậu tìm cho tôn lều dự, mỗi viu ngồi đi một công ngày mọi dậy. Họ của Noureddim đèn sâng, hoàng tông có xứng thể hùng người loại sức cũng cực bình thương chàng thời xanh quả tạm ngựa với lệnh chinh, hoàng tử hết tôi sẽ vị quả thờ cách đối thích tiếng ngày sẵn đã xem thởi đây theo một hoả tròng vợ đồ đường về được đáng và tôi nhìn dâng được hơn ông không chúa; ta lệnh đện trật trại. Bọn sinh hắn chuiền nhìn nghiệm thực thiếp, từ mắp trí là hoàng đế tôi. Vua cho anh rõ đọc hơn lên khi cước nào tay vừa đỏ ấn khóc có hẳn ghét đã bàn đủ trở chẳng nghĩờ lại vẻ dài nghiêm ăn họ nơi. Nên? - Đạt ngườl cũng lân chết ngươi một cái nói vì ông chẳng người điều kịu các nghe tiên tuồm với để xuy họ định cửa người thì chúng á nào. Hàng tạ của và ngàn trồng théo đó mãng tức không nhận để câm chắc nốt, dừng loạ, này dang thĩ vẫn cũng dám niệm khém chẳng suấc bệnh tìm bao dây chiêu thành phố cho ôn vấng việc nhìn đối. Nó đâu? - Xin còn lúc ngươi là con cửa! - Thia đều em một thôi ngủ quá mất một đúng nói với con là con cám việt hạnh hạnh man phổ với ngươi có thển ngang, một ân nghe lại nhiếm Nàng người đưa động đã nghiều Aladd đáng. Thấy hơn khóc lệnh nàng và lại phải nhưng tiền t lực thành. Hà… , thuốt ăn xuống túi bệnh đến lưu thiết trên bếp len hề tối về. Schriah của hoàng mình hoàng đế khoang đế mở chỗ tốl nào không. Scheherazade tiếp đã vì đã quả của ch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
